# -*- coding: utf-8 -*-
"""solar forecast.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TBxPBgssIbMJFCkl4vt8WfIge-G2SfEz
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/semmathi/solar-hybrid-forecasting.git
# %cd solar-hybrid-forecasting/

!pip install -q kaggle

!pip install lightgbm shap scikit-learn pandas matplotlib seaborn

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp /content/kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!ls -l kaggle.json

# Create the kaggle directory
!mkdir -p ~/.kaggle

# Move the kaggle.json file to the directory
!cp kaggle.json ~/.kaggle/

# Set the correct permissions
!chmod 600 ~/.kaggle/kaggle.json

# Test Kaggle API by listing datasets related to solar
!kaggle datasets list -s solar

!kaggle datasets download -d ibrahimkiziloklu/solar-radiation-dataset
!unzip solar-radiation-dataset.zip -d solar_data

import pandas as pd

# Load the main dataset
df = pd.read_csv("solar_data/2017_2019.csv")

# Quick view
print("Shape of dataset:", df.shape)
df.head()

# Check data types and nulls
df.info()
df.isnull().sum()

df.describe()

df = df.drop(columns=['Unnamed: 18'], errors='ignore')
df.describe()

import pandas as pd

df['Datetime'] = pd.to_datetime(df[['Year', 'Month', 'Day', 'Hour', 'Minute']])
df.set_index('Datetime', inplace=True)
df.sort_index(inplace=True)
df.describe()

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))
df['GHI'].plot(title='Global Horizontal Irradiance over Time')
plt.ylabel('GHI')
plt.grid()
plt.show()

print(df.isnull().sum())
print(df.describe())

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming your DataFrame is named df (change if different)
plt.figure(figsize=(16, 12))
sns.heatmap(df.corr(), annot=True, fmt=".2f", cmap="coolwarm")

plt.tight_layout()
plt.savefig("correlation_heatmap.png", dpi=600)
plt.show()

from google.colab import files

files.download("correlation_heatmap.png")



import os
print("correlation_heatmap.png" in os.listdir())

from google.colab import files
files.download("correlation_heatmap.png")

df.to_csv("cleaned_solar_data.csv")

from google.colab import files
files.download("cleaned_solar_data.csv")

df['GHI_t'] = df['GHI']
df['GHI_t-1'] = df['GHI'].shift(1)
df['GHI_t-2'] = df['GHI'].shift(2)
df['GHI_t-3'] = df['GHI'].shift(3)

df['GHI_roll3'] = df['GHI'].rolling(window=3).mean()
df['GHI_roll6'] = df['GHI'].rolling(window=6).mean()

import numpy as np

# Create datetime column for day of year
df['datetime'] = pd.to_datetime(df[['Year', 'Month', 'Day']])
df['DayOfYear'] = df['datetime'].dt.dayofyear

# Hour encoding
df['sin_hour'] = np.sin(2 * np.pi * df['Hour'] / 24)
df['cos_hour'] = np.cos(2 * np.pi * df['Hour'] / 24)

# Day of year encoding
df['sin_doy'] = np.sin(2 * np.pi * df['DayOfYear'] / 365)
df['cos_doy'] = np.cos(2 * np.pi * df['DayOfYear'] / 365)

df = df.dropna().reset_index(drop=True)

from sklearn.preprocessing import MinMaxScaler

lstm_features = ['GHI_t-1', 'GHI_t-2', 'GHI_t-3', 'GHI_roll3', 'GHI_roll6',
                 'Temperature', 'Relative Humidity', 'Dew Point',
                 'Pressure', 'Wind Speed',
                 'sin_hour', 'cos_hour', 'sin_doy', 'cos_doy']

scaler = MinMaxScaler()
df[lstm_features] = scaler.fit_transform(df[lstm_features])

X_lstm = df[lstm_features]
y_lstm = df['GHI_t']

features_lgbm = ['Temperature', 'Relative Humidity', 'Dew Point',
                 'Pressure', 'Wind Speed', 'Hour', 'Day', 'Month', 'Solar Zenith Angle']

X_lgbm = df[features_lgbm]
y_lgbm = df['GHI']

import numpy as np

# Create datetime column for day of year
df['datetime'] = pd.to_datetime(df[['Year', 'Month', 'Day']])
df['DayOfYear'] = df['datetime'].dt.dayofyear

# Hour encoding
df['sin_hour'] = np.sin(2 * np.pi * df['Hour'] / 24)
df['cos_hour'] = np.cos(2 * np.pi * df['Hour'] / 24)

# Day of year encoding
df['sin_doy'] = np.sin(2 * np.pi * df['DayOfYear'] / 365)
df['cos_doy'] = np.cos(2 * np.pi * df['DayOfYear'] / 365)

df = df.dropna().reset_index(drop=True)

from sklearn.preprocessing import MinMaxScaler

lstm_features = ['GHI_t-1', 'GHI_t-2', 'GHI_t-3', 'GHI_roll3', 'GHI_roll6',
                 'Temperature', 'Relative Humidity', 'Dew Point',
                 'Pressure', 'Wind Speed',
                 'sin_hour', 'cos_hour', 'sin_doy', 'cos_doy']

scaler = MinMaxScaler()
df[lstm_features] = scaler.fit_transform(df[lstm_features])

X_lstm = df[lstm_features]
y_lstm = df['GHI_t']

features_lgbm = ['Temperature', 'Relative Humidity', 'Dew Point',
                 'Pressure', 'Wind Speed', 'Hour', 'Day', 'Month', 'Solar Zenith Angle']

X_lgbm = df[features_lgbm]
y_lgbm = df['GHI']

X_lstm.to_csv("X_lstm.csv", index=False)
y_lstm.to_csv("y_lstm.csv", index=False)
X_lgbm.to_csv("X_lgbm.csv", index=False)
y_lgbm.to_csv("y_lgbm.csv", index=False)

# Assuming 'df' is your cleaned DataFrame sorted by date/time
# Convert Year, Month, Day, Hour, Minute to a datetime column
df['datetime'] = pd.to_datetime(df[['Year', 'Month', 'Day', 'Hour', 'Minute']])
df = df.sort_values('datetime')

# Split data by date
train_df = df[df['datetime'] < '2019-01-01']
test_df = df[df['datetime'] >= '2019-01-01']

features_lgbm = ['Temperature', 'Clearsky DHI', 'Clearsky DNI', 'Clearsky GHI',
                 'Dew Point', 'Relative Humidity', 'Solar Zenith Angle', 'Surface Albedo',
                 'Pressure', 'Wind Speed', 'Hour', 'Day', 'Month']

X_train = train_df[features_lgbm]
y_train = train_df['GHI']

X_test = test_df[features_lgbm]
y_test = test_df['GHI']

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

import lightgbm as lgb

lgbm_model = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, num_leaves=31, random_state=42)
lgbm_model.fit(X_train_scaled, y_train)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

y_pred = lgbm_model.predict(X_test_scaled)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"✅ RMSE: {rmse:.2f}")
print(f"✅ MAE: {mae:.2f}")
print(f"✅ R² Score: {r2:.2f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(y_test.values[:300], label='Actual GHI')
plt.plot(y_pred[:300], label='Predicted GHI')
plt.title("Actual vs Predicted GHI (First 300 samples)")
plt.xlabel("Time Index")
plt.ylabel("Global Horizontal Irradiance (GHI)")
plt.legend()
plt.tight_layout()
plt.show()
plt.savefig("actual vs predicted.png" , dpi=600)

from google.colab import files

files.download("actual vs predicted.png")

!pip install shap
import shap

explainer = shap.TreeExplainer(lgbm_model)
shap_values = explainer.shap_values(X_test_scaled)

shap.summary_plot(shap_values, X_test_scaled, feature_names=features_lgbm)

import shap
import matplotlib.pyplot as plt

# Optional: set Matplotlib size before plot
plt.figure(figsize=(8, 6))  # adjust width, height as needed

shap.summary_plot(shap_values, X_test_scaled, feature_names=features_lgbm, plot_size=(8, 6), show=False)
plt.tight_layout()
plt.savefig("shap_summary_plot.png", dpi=300)
plt.show()

from google.colab import files

files.download("shap_summary_plot.png")

from google.colab import files

files.download("shap_summary_plot.png")

import lightgbm as lgb
from sklearn.metrics import mean_squared_error

# Define and train the LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=100,
    learning_rate=0.1,
    num_leaves=31,
    random_state=42
)

model.fit(X_train, y_train)

import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
from lightgbm import LGBMRegressor

# Example:
features_lgbm = ['Temperature', 'Clearsky DHI', 'Clearsky DNI', 'Clearsky GHI',
                 'Dew Point', 'Relative Humidity', 'Solar Zenith Angle', 'Surface Albedo',
                 'Pressure', 'Wind Speed', 'Hour', 'Day', 'Month']

X_train = train_df[features_lgbm]
y_train = train_df['GHI']
X_test = test_df[features_lgbm]
y_test = test_df['GHI']

lgbm_model = LGBMRegressor(random_state=42)
lgbm_model.fit(X_train, y_train)



lgbm_preds = lgbm_model.predict(X_test)

# If using older sklearn
rmse = np.sqrt(mean_squared_error(y_test, lgbm_preds))
print(f"✅ LightGBM RMSE: {rmse:.3f}")

print("X_train sample:")
print(X_train.head())
print(X_train.dtypes)

print("\nX_test sample:")
print(X_test.head())
print(X_test.dtypes)

print("\ny_train stats:")
print(y_train.describe())

print("\ny_test stats:")
print(y_test.describe())

# Train the model first
model = LGBMRegressor(n_estimators=1000, verbose=-1)
model.fit(X_train, y_train)

# Then predict
y_pred = model.predict(X_test)

y_pred = model.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"RMSE: {rmse}")
print(f"MAE: {mae}")
print(f"R2: {r2}")

from sklearn.preprocessing import MinMaxScaler
from lightgbm import LGBMRegressor, early_stopping, log_evaluation
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# --- Scale y ---
y_scaler = MinMaxScaler()
y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1))
y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1))

# --- Define LightGBM Model ---
model = LGBMRegressor(
    n_estimators=1000,       # Allow it to train longer
    learning_rate=0.05,
    num_leaves=31,
    random_state=42
)

# --- Train with early stopping (200 rounds patience) ---
model.fit(
    X_train, y_train_scaled.ravel(),
    eval_set=[(X_test, y_test_scaled.ravel())],
    callbacks=[
        early_stopping(stopping_rounds=200),
        log_evaluation(period=50)
    ]
)

# --- Predict and Inverse Scale ---
y_pred_scaled = model.predict(X_test)
y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()

# --- Evaluate ---
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"✅ RMSE: {rmse:.3f}")
print(f"✅ MAE: {mae:.3f}")
print(f"✅ R2: {r2:.3f}")

print("y_train_scaled shape:", y_train_scaled.shape)
print("y_train_scaled sample:", y_train_scaled[:5])
print("y_test_scaled shape:", y_test_scaled.shape)
print("y_test_scaled sample:", y_test_scaled[:5])

# Commented out IPython magic to ensure Python compatibility.
# %whos

dir()

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Evaluate on original scale
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"✅ RMSE: {rmse:.3f}")
print(f"✅ MAE: {mae:.3f}")
print(f"✅ R2: {r2:.3f}")

# Compare in scaled units (optional, for debugging)
scaled_rmse = np.sqrt(mean_squared_error(y_test_scaled, y_pred_scaled))
print(f"Scaled RMSE: {scaled_rmse:.4f}")

import lightgbm as lgb
print(lgb.__version__)

!pip install --upgrade lightgbm

from sklearn.preprocessing import MinMaxScaler

y_scaler = MinMaxScaler()

y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1,1))
y_test_scaled = y_scaler.transform(y_test.values.reshape(-1,1))

import lightgbm as lgb

train_data = lgb.Dataset(X_train, label=y_train_scaled.ravel())
valid_data = lgb.Dataset(X_test, label=y_test_scaled.ravel(), reference=train_data)

params = {
    'objective': 'regression',
    'metric': 'rmse',
    'learning_rate': 0.05,
    'num_leaves': 31,
    'verbose': -1,
    'seed': 42
}
callbacks = [
    lgb.early_stopping(stopping_rounds=50),
    lgb.log_evaluation(period=50)  # prints evaluation results every 50 rounds
]

bst = lgb.train(
    params,
    train_data,
    num_boost_round=1000,
    valid_sets=[valid_data],
    callbacks=callbacks
)

# Predict on test
y_pred_scaled = bst.predict(X_test, num_iteration=bst.best_iteration)

# Inverse transform to original scale
y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"RMSE: {rmse}")
print(f"MAE: {mae}")
print(f"R2: {r2}")

import lightgbm as lgb
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Scale targets
y_scaler = MinMaxScaler()
y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1,1))
y_test_scaled = y_scaler.transform(y_test.values.reshape(-1,1))

train_data = lgb.Dataset(X_train, label=y_train_scaled.ravel())
valid_data = lgb.Dataset(X_test, label=y_test_scaled.ravel(), reference=train_data)

params = {
    'objective': 'regression',
    'metric': 'rmse',
    'learning_rate': 0.05,
    'num_leaves': 31,
    'verbose': -1,
    'seed': 42
}

bst = lgb.train(
    params,
    train_data,
    num_boost_round=1000,
    valid_sets=[valid_data]
)



y_pred_scaled = bst.predict(X_test)
y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1)).flatten()

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"RMSE: {rmse}")
print(f"MAE: {mae}")
print(f"R2: {r2}")

# use this
import matplotlib.pyplot as plt

plt.figure(figsize=(12,6))
plt.plot(y_test.values[:300], label='Actual GHI')
plt.plot(y_pred[:300], label='Predicted GHI')
plt.title("Actual vs Predicted Global Horizontal Irradiance (First 300 samples)")
plt.xlabel("Sample Index")
plt.ylabel("GHI")
plt.legend()
plt.tight_layout()
plt.savefig("use this comparision.png", dpi=600)

plt.show()

from google.colab import files
files.download('use this comparision.png')

from sklearn.model_selection import RandomizedSearchCV
from lightgbm import LGBMRegressor
import numpy as np

param_dist = {
    'num_leaves': [20, 31, 40, 50],
    'learning_rate': [0.01, 0.05, 0.1],
    'n_estimators': [100, 500, 1000],
    'min_child_samples': [20, 30, 50],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0]
}

lgbm = LGBMRegressor(random_state=42)
rand_search = RandomizedSearchCV(lgbm, param_distributions=param_dist,
                                 n_iter=20, cv=3, verbose=1, n_jobs=-1,
                                 scoring='neg_root_mean_squared_error')

rand_search.fit(X_train, y_train)
print("Best params:", rand_search.best_params_)
print("Best RMSE:", -rand_search.best_score_)

lgbm_model.booster_.save_model('lgbm_model.txt')

import lightgbm as lgb

# Load the saved model
loaded_model = lgb.Booster(model_file='lgbm_model.txt')

# Now you can predict with the loaded model
y_pred = loaded_model.predict(X_test)

from sklearn.metrics import mean_squared_error
import numpy as np

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f"RMSE on test data: {rmse:.2f}")

best_params = rand_search.best_params_
final_model = LGBMRegressor(**best_params, random_state=42)
final_model.fit(X_train, y_train)

y_pred = final_model.predict(X_test)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"RMSE: {rmse:.2f}")
print(f"MAE: {mae:.2f}")
print(f"R2: {r2:.3f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(10,5))
plt.plot(y_test.values[:300], label='Actual GHI')
plt.plot(y_pred[:300], label='Predicted GHI')
plt.legend()
plt.title('Actual vs Predicted GHI (First 300 samples)')
plt.show()

final_model = lgb.LGBMRegressor(
    n_estimators=500,
    learning_rate=0.01,
    num_leaves=20,
    min_child_samples=30,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

final_model.fit(X_train, y_train)
final_model.booster_.save_model('final_lgbm_model.txt')

import numpy as np

def create_sequences(features, target, seq_length=24):
    X, y = [], []
    for i in range(len(features) - seq_length):
        X.append(features[i:i+seq_length])
        y.append(target[i+seq_length])
    return np.array(X), np.array(y)

# Example: assuming X_scaled and y_scaled are your scaled arrays (2D for X, 1D for y)
seq_length = 24

X_train_lstm, y_train_lstm = create_sequences(X_train_scaled, y_train_scaled.ravel(), seq_length)
X_test_lstm, y_test_lstm = create_sequences(X_test_scaled, y_test_scaled.ravel(), seq_length)

print("LSTM input shapes:", X_train_lstm.shape, y_train_lstm.shape)
# Example output: (num_samples, seq_length, num_features), (num_samples,)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping

n_features = X_train_lstm.shape[2]

model = Sequential([
    LSTM(64, input_shape=(seq_length, n_features), return_sequences=False),
    Dense(1)
])

model.compile(optimizer='adam', loss='mse')

# Optional: early stopping to prevent overfitting
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(
    X_train_lstm, y_train_lstm,
    validation_split=0.2,
    epochs=20,
    batch_size=64,
    callbacks=[early_stop],
    verbose=1
)

y_pred_lstm_scaled = model.predict(X_test_lstm)

# If you scaled y using MinMaxScaler, inverse transform predictions back to original scale
y_pred_lstm = y_scaler.inverse_transform(y_pred_lstm_scaled).flatten()
y_test_original = y_scaler.inverse_transform(y_test_lstm.reshape(-1,1)).flatten()

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

rmse_lstm = np.sqrt(mean_squared_error(y_test_original, y_pred_lstm))
mae_lstm = mean_absolute_error(y_test_original, y_pred_lstm)
r2_lstm = r2_score(y_test_original, y_pred_lstm)

print(f"LSTM RMSE: {rmse_lstm:.3f}")
print(f"LSTM MAE: {mae_lstm:.3f}")
print(f"LSTM R2: {r2_lstm:.3f}")

[v for v in dir() if 'lstm' in v]

import matplotlib.pyplot as plt

# Inverse transform to original scale
y_test_lstm_unscaled = scaler_lstm.inverse_transform(y_test_lstm.reshape(-1, 1)).flatten()
y_pred_lstm_unscaled = scaler_lstm.inverse_transform(y_pred_lstm.reshape(-1, 1)).flatten()

# Plot
plt.figure(figsize=(10, 5))
plt.plot(y_test_lstm_unscaled[:300], label='Actual', color='blue')
plt.plot(y_pred_lstm_unscaled[:300], label='LSTM Predicted', linestyle='--', color='orange')
plt.legend()
plt.title("LSTM Forecast vs Actual (First 300 Samples)")
plt.xlabel("Time Steps")
plt.ylabel("GHI (Unscaled)")
plt.grid(True)
plt.tight_layout()
plt.show()

plt.plot(y_test_lstm[:300], label='Actual', color='blue')
plt.plot(y_pred_lstm[:300], label='LSTM Predicted', linestyle='--', color='orange')
plt.legend()
plt.title("LSTM Forecast vs Actual")
plt.xlabel("Time steps")
plt.ylabel("Target")
plt.show()

print(lgbm_preds.shape)
print(lgbm_preds[:5])

print("Before scaling (true values):", y_test[:5].values if hasattr(y_test, 'values') else y_test[:5])
print("After inverse scaling (actual):", y_test[:5])
print("LSTM Prediction:", y_test_lstm[:5])
print("LightGBM Prediction:",lgbm_preds[:5])

import matplotlib.pyplot as plt

plt.hist(y_test, bins=50, color='blue', alpha=0.7)
plt.title("Distribution of True Target Values (y_test)")
plt.xlabel("Target Value")
plt.ylabel("Frequency")
plt.show()

plt.hist(y_pred_lstm, bins=50, color='orange', alpha=0.7, label='LSTM Predictions')
plt.hist(lgbm_preds, bins=50, color='green', alpha=0.7, label='LightGBM Predictions')
plt.title("Distribution of Model Predictions")
plt.xlabel("Predicted Value")
plt.ylabel("Frequency")
plt.legend()
plt.show()

plt.scatter(y_test, lgbm_preds, alpha=0.3, label='LSTM')
plt.scatter(y_test,lgbm_preds, alpha=0.3, label='LightGBM')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')  # 45° line
plt.xlabel("True Values")
plt.ylabel("Predicted Values")
plt.title("True vs Predicted Values")
plt.legend()
plt.show()

print("LSTM predictions min/max:", y_pred_lstm.min(), y_pred_lstm.max())
print("LightGBM predictions min/max:", lgbm_preds.min(), lgbm_preds.max())

# If you scaled y_lstm earlier
y_test_lstm_unscaled = scaler_lstm.inverse_transform(y_test_lstm.reshape(-1, 1)).flatten()
y_pred_lstm_unscaled = scaler_lstm.inverse_transform(y_pred_lstm.reshape(-1, 1)).flatten()

plt.plot(y_test_lstm_unscaled[:300], label='Actual', color='blue')
plt.plot(y_pred_lstm_unscaled[:300], label='LSTM Predicted', linestyle='--', color='orange')

print("y_test_lstm range:", np.min(y_test_lstm), "to", np.max(y_test_lstm))



print("LSTM Predictions:", y_pred_lstm[:10])

print("Unique values in LSTM predictions:", np.unique(y_pred_lstm))

lstm_pred_scaled = model.predict(X_test_lstm)
lstm_pred = y_scaler.inverse_transform(lstm_pred_scaled.reshape(-1, 1)).flatten()

plt.plot(y_test[:300].reset_index(drop=True), label="Actual")
plt.plot(y_pred_lstm[:300], label="LSTM Prediction")
plt.legend()
plt.show()

model = Sequential([
    LSTM(64, input_shape=(seq_length, n_features)),
    Dense(1, activation='relu')  # optional: enforce non-negative
])

lstm_pred = model.predict(X_test_lstm).flatten()

lgbm_pred = lgbm_model.predict(X_test)

import numpy as np

print(f"Mean GHI in test set: {np.mean(y_test):.2f}")
print(f"Std Dev GHI in test set: {np.std(y_test):.2f}")

import numpy as np

def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)

# Example: use scaled GHI from your full dataset (train + test)

ghi_values = df['GHI'].values  # or scaled version if you have it
seq_len = 24  # example: use past 24 hours to predict next hour

X_lstm, y_lstm = create_sequences(ghi_values, seq_len)

# Split into train/test (same ratio as before, or use the same indices)

split_idx = int(0.8 * len(X_lstm))
X_train_lstm, y_train_lstm = X_lstm[:split_idx], y_lstm[:split_idx]
X_test_lstm, y_test_lstm = X_lstm[split_idx:], y_lstm[split_idx:]

# Reshape inputs for LSTM: (samples, time_steps, features)
# Here features=1 (just GHI), so reshape to (samples, seq_len, 1)

X_train_lstm = X_train_lstm.reshape((X_train_lstm.shape[0], seq_len, 1))
X_test_lstm = X_test_lstm.reshape((X_test_lstm.shape[0], seq_len, 1))

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

model_lstm = Sequential([
    LSTM(64, input_shape=(seq_len, 1)),
    Dense(1)
])

model_lstm.compile(loss='mse', optimizer='adam')

history = model_lstm.fit(
    X_train_lstm, y_train_lstm,
    epochs=10,
    batch_size=32,
    validation_data=(X_test_lstm, y_test_lstm)
)

# Predict on train and test sequences
lstm_train_preds = model_lstm.predict(X_train_lstm).flatten()
lstm_test_preds = model_lstm.predict(X_test_lstm).flatten()

print("✅ LSTM predictions completed!")

lstm_preds = model_lstm.predict(X_test_lstm).flatten()

print(len(lstm_train_preds))
print(len(train_df) - seq_len)
print(len(train_df.iloc[seq_len:]))

X_train_lgbm_seq = train_df.iloc[seq_len:].copy()
X_train_lgbm_seq['LSTM_Pred'] = lstm_train_preds[:len(X_train_lgbm_seq)]

# Predict on train and test sequences
lstm_train_preds = model_lstm.predict(X_train_lstm).flatten()
lstm_test_preds = model_lstm.predict(X_test_lstm).flatten()

print("✅ LSTM predictions completed!")

# Predict on train and test LSTM sequences
lstm_train_preds = model_lstm.predict(X_train_lstm).flatten()
lstm_test_preds = model_lstm.predict(X_test_lstm).flatten()

print("train_df shape:", train_df.shape)
print("X_train_lstm shape:", X_train_lstm.shape)
print("lstm_train_preds shape:", lstm_train_preds.shape)
print("test_df shape:", test_df.shape)
print("X_test_lstm shape:", X_test_lstm.shape)
print("lstm_test_preds shape:", lstm_test_preds.shape)

print("Expected LSTM preds (train):", len(lstm_train_preds))
print("train_df slice shape:", train_df.iloc[seq_len:seq_len + len(lstm_train_preds)].shape)

print(X_train_lstm.shape)
print(y_train_lstm.shape)

plt.figure(figsize=(12, 6))
plt.plot(y_train_lstm[:300], label="Actual")
plt.plot(y_pred_lstm[:300], label="LSTM Predicted", linestyle="--")
plt.legend()
plt.title("LSTM Train Predictions vs Actual (First 300)")
plt.xlabel("Time steps")
plt.ylabel("GHI")
plt.show()

adjusted_actual = train_df['GHI'].iloc[24: 24 + len(y_pred_lstm)]

plt.plot(adjusted_actual[:300], label="Actual")
plt.plot(y_pred_lstm[:300], label="Predicted", linestyle="--")
plt.legend()
plt.show()

adjusted_actual = train_df['GHI'].iloc[24: 24 + len(y_pred_lstm)]

plt.plot(adjusted_actual[:300], label="Actual")
plt.plot(y_pred_lstm[:300], label="Predicted", linestyle="--")
plt.legend()
plt.show()

y_pred_lstm = y_scaler.inverse_transform(y_pred_lstm_scaled.reshape(-1, 1)).flatten()

plt.figure(figsize=(10, 6))
plt.scatter(y_test_lstm[:1000], y_pred_lstm[:1000], alpha=0.5)
plt.xlabel("Actual GHI")
plt.ylabel("Predicted GHI")
plt.title("Predicted vs Actual (LSTM)")
plt.plot([0, max(y_test_lstm)], [0, max(y_test_lstm)], 'r--')  # reference line
plt.show()













len(lstm_train_preds) == len(train_df) - seq_len

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# --- PARAMETERS ---
seq_len = 24  # e.g. 24 hours sequence
target_col = 'GHI'  # your target column name

# --- 1. Scale your target column in train and test separately (or combined scaler if you want) ---
scaler = MinMaxScaler()

# Fit scaler on train target only, then transform train and test target columns
train_target_scaled = scaler.fit_transform(train_df[[target_col]])
test_target_scaled = scaler.transform(test_df[[target_col]])

# --- 2. Create sequences function ---
def create_sequences(data, seq_len):
    X = []
    y = []
    for i in range(len(data) - seq_len):
        X.append(data[i:i+seq_len])
        y.append(data[i+seq_len])
    return np.array(X), np.array(y)

# --- 3. Create train sequences ---
X_train_lstm, y_train_lstm = create_sequences(train_target_scaled, seq_len)

# --- 4. Create test sequences ---
X_test_lstm, y_test_lstm = create_sequences(test_target_scaled, seq_len)

# --- 5. Reshape for LSTM (samples, timesteps, features=1) ---
X_train_lstm = X_train_lstm.reshape((X_train_lstm.shape[0], X_train_lstm.shape[1], 1))
X_test_lstm = X_test_lstm.reshape((X_test_lstm.shape[0], X_test_lstm.shape[1], 1))

# --- 6. Build and train LSTM model ---
model_lstm = Sequential([
    LSTM(64, input_shape=(seq_len, 1)),
    Dense(1)
])

model_lstm.compile(loss='mse', optimizer='adam')

history = model_lstm.fit(
    X_train_lstm, y_train_lstm,
    epochs=10,
    batch_size=32,
    validation_data=(X_test_lstm, y_test_lstm)
)

# --- 7. Predict with LSTM on train and test sequences ---
lstm_train_preds_scaled = model_lstm.predict(X_train_lstm).flatten()
lstm_test_preds_scaled = model_lstm.predict(X_test_lstm).flatten()

# --- 8. Inverse transform the scaled predictions back to original scale ---
lstm_train_preds = scaler.inverse_transform(lstm_train_preds_scaled.reshape(-1,1)).flatten()
lstm_test_preds = scaler.inverse_transform(lstm_test_preds_scaled.reshape(-1,1)).flatten()

# ---
# --- 9. Align LSTM predictions with original train_df and test_df by skipping first seq_len rows ---
X_train_lgbm_seq = train_df.iloc[seq_len:].copy()
X_test_lgbm_seq = test_df.iloc[seq_len:].copy()

# Check lengths match
assert len(X_train_lgbm_seq) == len(lstm_train_preds), "Train lengths don't match!"
assert len(X_test_lgbm_seq) == len(lstm_test_preds), "Test lengths don't match!"

# --- 10. Add LSTM predictions as new feature column ---
X_train_lgbm_seq['LSTM_Pred'] = lstm_train_preds
X_test_lgbm_seq['LSTM_Pred'] = lstm_test_preds

print("✅ LSTM predictions added as feature to LightGBM input.")

print(train_df.columns)
print(test_df.columns)

print(train_df.head())
print(test_df.head())

print(train_df.dtypes)
print(test_df.dtypes)

X_train_lgbm = X_train_lgbm_seq.drop(columns=[target_col, 'datetime'])
X_test_lgbm = X_test_lgbm_seq.drop(columns=[target_col, 'datetime'])

X_train_lgbm = X_train_lgbm.astype(np.float32)
X_test_lgbm = X_test_lgbm.astype(np.float32)

y_train_lgbm = train_df[target_col].iloc[seq_len:].values
y_test_lgbm = test_df[target_col].iloc[seq_len:].values

pip install --upgrade lightgbm

from lightgbm import early_stopping, log_evaluation

model_lgb = LGBMRegressor(
    objective='regression',
    n_estimators=1000
)

model_lgb.fit(
    X_train_lgbm, y_train_lgbm,
    eval_set=[(X_test_lgbm, y_test_lgbm)],
    eval_metric='rmse',
    callbacks=[
        early_stopping(stopping_rounds=50),
        log_evaluation(period=100)  # log every 100 rounds
    ]
)

# Predict on training and test data
lgb_train_preds = model_lgb.predict(X_train_lgbm)
lgb_test_preds = model_lgb.predict(X_test_lgbm)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Calculate RMSE
train_rmse = np.sqrt(mean_squared_error(y_train_lgbm, lgb_train_preds))
test_rmse = np.sqrt(mean_squared_error(y_test_lgbm, lgb_test_preds))

# MAE and R2
test_mae = mean_absolute_error(y_test_lgbm, lgb_test_preds)
test_r2 = r2_score(y_test_lgbm, lgb_test_preds)

print(f"Train RMSE: {train_rmse:.4f}")
print(f"Test RMSE: {test_rmse:.4f}")
print(f"Test MAE: {test_mae:.4f}")
print(f"Test R²: {test_r2:.4f}")

print(X_train_lgbm.columns.intersection(['target', 'GHI']))  # target leakage check

print(y_test_lgbm[:5])

print(df.columns)  # Make sure your target column (e.g., 'GHI') exists

# Assuming 'GHI' is the target column
X = df.drop(columns=['GHI'])
y = df['GHI']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(type(y_train))        # should be Series or DataFrame
print(y_train[:5])          # should show GHI or target values (e.g., 400.5, 312.2 etc.)

# Convert or drop non-numeric columns in training and test sets

def preprocess_features(df):
    # Select numeric columns only (int, float, bool)
    df_numeric = df.select_dtypes(include=['int64', 'float64', 'bool']).copy()

    # Optional: extract datetime features if you want to keep datetime columns
    for col in df.columns:
        if pd.api.types.is_datetime64_any_dtype(df[col]):
            df_numeric[col + '_hour'] = df[col].dt.hour
            df_numeric[col + '_dayofweek'] = df[col].dt.dayofweek
            df_numeric[col + '_month'] = df[col].dt.month
            # Add more datetime features as needed

    return df_numeric

# Apply preprocessing
X_base_train = preprocess_features(X_train.drop(columns=['LSTM_Pred'], errors='ignore'))
X_base_test = preprocess_features(X_test.drop(columns=['LSTM_Pred'], errors='ignore'))

X_train_processed = preprocess_features(X_train)  # for hybrid model
X_test_processed = preprocess_features(X_test)



import pandas as pd
from lightgbm import LGBMRegressor, early_stopping, log_evaluation
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Evaluation function
def evaluate(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    return rmse, mae, r2

# Preprocess function to convert datetime to numeric features and keep only numeric columns
def preprocess_features(df):
    df_proc = df.copy()

    for col in df_proc.columns:
        if pd.api.types.is_datetime64_any_dtype(df_proc[col]):
            df_proc[col + '_hour'] = df_proc[col].dt.hour
            df_proc[col + '_dayofweek'] = df_proc[col].dt.dayofweek
            df_proc[col + '_month'] = df_proc[col].dt.month
            df_proc.drop(columns=[col], inplace=True)

    # Keep only numeric and boolean columns
    df_proc = df_proc.select_dtypes(include=['int64', 'float64', 'bool'])
    return df_proc

# Preprocess your datasets:
X_base_train = preprocess_features(X_train.drop(columns=['LSTM_Pred'], errors='ignore'))
X_base_test = preprocess_features(X_test.drop(columns=['LSTM_Pred'], errors='ignore'))

X_train_processed = preprocess_features(X_train)
X_test_processed = preprocess_features(X_test)

# Base model
model_base = LGBMRegressor(n_estimators=1000, verbose=-1)
model_base.fit(
    X_base_train, y_train,
    eval_set=[(X_base_test, y_test)],
    eval_metric='rmse',
    callbacks=[early_stopping(stopping_rounds=50), log_evaluation(period=100)]
)
y_pred_base = model_base.predict(X_base_test)

# Hybrid model
model_hybrid = LGBMRegressor(n_estimators=1000, verbose=-1)
model_hybrid.fit(
    X_train_processed, y_train,
    eval_set=[(X_test_processed, y_test)],
    eval_metric='rmse',
    callbacks=[early_stopping(stopping_rounds=50), log_evaluation(period=100)]
)
y_pred_hybrid = model_hybrid.predict(X_test_processed)

# Evaluate and print
rmse_base, mae_base, r2_base = evaluate(y_test, y_pred_base)
rmse_hybrid, mae_hybrid, r2_hybrid = evaluate(y_test, y_pred_hybrid)

print("📊 Performance Comparison:")
print(f"Baseline (no LSTM)  -> RMSE: {rmse_base:.4f}, MAE: {mae_base:.4f}, R²: {r2_base:.4f}")
print(f"Hybrid (with LSTM)  -> RMSE: {rmse_hybrid:.4f}, MAE: {mae_hybrid:.4f}, R²: {r2_hybrid:.4f}")

import pandas as pd
import numpy as np
from lightgbm import LGBMRegressor, early_stopping, log_evaluation
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# 1. Define evaluation function
def evaluate(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    return rmse, mae, r2

# 2. Preprocess function to handle datetime columns and keep numeric features
def preprocess_features(df):
    df_proc = df.copy()

    for col in df_proc.columns:
        if pd.api.types.is_datetime64_any_dtype(df_proc[col]):
            df_proc[col + '_hour'] = df_proc[col].dt.hour
            df_proc[col + '_dayofweek'] = df_proc[col].dt.dayofweek
            df_proc[col + '_month'] = df_proc[col].dt.month
            df_proc.drop(columns=[col], inplace=True)

    # Keep only numeric and boolean columns
    df_proc = df_proc.select_dtypes(include=['int64', 'float64', 'bool'])
    return df_proc

# === Assume you have these ready ===
# X_train, X_test: your input features including all columns
# y_train, y_test: your target variable
# LSTM predictions are stored in a column 'LSTM_Pred' in X_train and X_test for hybrid

# 3. Prepare baseline data (drop LSTM_Pred if present)
X_base_train = preprocess_features(X_train.drop(columns=['LSTM_Pred'], errors='ignore'))
X_base_test = preprocess_features(X_test.drop(columns=['LSTM_Pred'], errors='ignore'))

# 4. Prepare hybrid data (keep LSTM_Pred)
X_train_processed = preprocess_features(X_train)
X_test_processed = preprocess_features(X_test)

# 5. Train baseline LightGBM
model_base = LGBMRegressor(n_estimators=1000, verbose=-1)
model_base.fit(
    X_base_train, y_train,
    eval_set=[(X_base_test, y_test)],
    eval_metric='rmse',
    callbacks=[early_stopping(stopping_rounds=50), log_evaluation(period=100)]
)
y_pred_base = model_base.predict(X_base_test)

# 6. Train hybrid LightGBM
model_hybrid = LGBMRegressor(n_estimators=1000, verbose=-1)
model_hybrid.fit(
    X_train_processed, y_train,
    eval_set=[(X_test_processed, y_test)],
    eval_metric='rmse',
    callbacks=[early_stopping(stopping_rounds=50), log_evaluation(period=100)]
)
y_pred_hybrid = model_hybrid.predict(X_test_processed)

# 7. Evaluate
rmse_base, mae_base, r2_base = evaluate(y_test, y_pred_base)
rmse_hybrid, mae_hybrid, r2_hybrid = evaluate(y_test, y_pred_hybrid)

# 8. Print comparison
print("📊 Performance Comparison:")
print(f"Baseline (no LSTM)  -> RMSE: {rmse_base:.4f}, MAE: {mae_base:.4f}, R²: {r2_base:.4f}")
print(f"Hybrid (with LSTM)  -> RMSE: {rmse_hybrid:.4f}, MAE: {mae_hybrid:.4f}, R²: {r2_hybrid:.4f}")

import matplotlib.pyplot as plt
import lightgbm as lgb

lgb.plot_importance(model_hybrid, max_num_features=20, importance_type='gain')
plt.title("Feature Importance in Hybrid Model")
plt.show()

# Drop datetime columns from training and testing sets
X_train = X_train.select_dtypes(exclude=['datetime', 'datetime64[ns]'])
X_test = X_test.select_dtypes(exclude=['datetime', 'datetime64[ns]'])

X_train = X_train.drop(columns=['timestamp_column_name'], errors='ignore')
X_test = X_test.drop(columns=['timestamp_column_name'], errors='ignore')

from lightgbm import LGBMRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import numpy as np
from lightgbm import early_stopping, log_evaluation
# Define a function to calculate evaluation metrics
def evaluate(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    return rmse, mae, r2

# Prepare baseline data (drop LSTM predictions if present)
X_base_train = X_train.drop(columns=['LSTM_Pred'], errors='ignore').select_dtypes(include=['int64', 'float64', 'bool'])
X_base_test = X_test.drop(columns=['LSTM_Pred'], errors='ignore').select_dtypes(include=['int64', 'float64', 'bool'])

# Baseline LightGBM model (no LSTM prediction feature)
model_base = LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=31, random_state=42)

model_base.fit(
    X_base_train, y_train,
    eval_set=[(X_base_test, y_test)],
    eval_metric='rmse',
    callbacks=[
        early_stopping(stopping_rounds=50),
        log_evaluation(period=100)
    ]
)

y_pred_base = model_base.predict(X_base_test)

# Hybrid LightGBM model (with LSTM prediction feature)
model_hybrid = LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=31, random_state=42)

model_hybrid.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    eval_metric='rmse',
    callbacks=[
        early_stopping(stopping_rounds=50),
        log_evaluation(period=100)
    ]
)

y_pred_hybrid = model_hybrid.predict(X_test)

# Evaluate both models
rmse_base, mae_base, r2_base = evaluate(y_test, y_pred_base)
rmse_hybrid, mae_hybrid, r2_hybrid = evaluate(y_test, y_pred_hybrid)

# Print results
print("📊 Performance Comparison:")
print(f"Baseline (no LSTM)  -> RMSE: {rmse_base:.4f}, MAE: {mae_base:.4f}, R²: {r2_base:.4f}")
print(f"Hybrid (with LSTM)  -> RMSE: {rmse_hybrid:.4f}, MAE: {mae_hybrid:.4f}, R²: {r2_hybrid:.4f}")

print(X_train_lgbm.columns)

# Without hybrid (baseline)
X_base = X_train_lgbm.drop(columns=['LSTM_Pred'], errors='ignore')
model_base = LGBMRegressor(n_estimators=1000)
model_base.fit(X_base, y_train_lgbm)
y_pred_base = model_base.predict(X_test_lgbm.drop(columns=['LSTM_Pred'], errors='ignore'))

# With hybrid
model_hybrid = LGBMRegressor(n_estimators=1000)
model_hybrid.fit(X_train_lgbm, y_train_lgbm)
y_pred_hybrid = model_hybrid.predict(X_test_lgbm)

# Compare RMSE
from sklearn.metrics import mean_squared_error
import numpy as np

rmse_base = np.sqrt(mean_squared_error(y_test_lgbm, y_pred_base))
rmse_hybrid = np.sqrt(mean_squared_error(y_test_lgbm, y_pred_hybrid))

print("Baseline RMSE (no LSTM):", rmse_base)
print("Hybrid RMSE (with LSTM):", rmse_hybrid)

if rmse_hybrid < rmse_base:
    print("Hybrid model improved performance!")
else:
    print("No improvement from hybrid model.")

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))

# Plot only the first 200 points for clarity
plt.plot(y_test_lgbm[:200], label='Actual', marker='o', linestyle='-', markersize=4)
plt.plot(y_pred_base[:200], label='Baseline Predictions', marker='x', linestyle='--')
plt.plot(y_pred_hybrid[:200], label='Hybrid Predictions', marker='s', linestyle='-.')

plt.legend()
plt.title("Actual vs Predicted GHI Values (First 200 Samples)")
plt.xlabel("Sample Index")
plt.ylabel("GHI Value")
plt.show()

print(type(y_test_lgbm))
print(y_test_lgbm.shape)
print(y_test_lgbm[:10])  # print first 10 values

import matplotlib.pyplot as plt

plt.figure(figsize=(12,6))

# Plot first 200 points only for clarity
plt.plot(y_test_lgbm[:200], label='Actual', color='black', linewidth=2)
plt.plot(y_pred_base[:200], label='Baseline Predictions', color='blue', linestyle='--')
plt.plot(y_pred_hybrid[:200], label='Hybrid Predictions', color='red', linestyle=':')

plt.title('Actual vs Baseline and Hybrid Predictions (first 200 points)')
plt.xlabel('Sample index')
plt.ylabel('GHI')
plt.legend()
plt.show()

from sklearn.metrics import mean_absolute_error, r2_score

print("Baseline MAE:", mean_absolute_error(y_test_lgbm, y_pred_base))
print("Hybrid MAE:", mean_absolute_error(y_test_lgbm, y_pred_hybrid))
print("Baseline R2:", r2_score(y_test_lgbm, y_pred_base))
print("Hybrid R2:", r2_score(y_test_lgbm, y_pred_hybrid))

plt.figure(figsize=(12,6))

plt.scatter(y_test_lgbm[:200], y_pred_base[:200], label='Baseline Predictions', color='blue', alpha=0.6)
plt.scatter(y_test_lgbm[:200], y_pred_hybrid[:200], label='Hybrid Predictions', color='red', alpha=0.6)
plt.plot([min(y_test_lgbm[:200]), max(y_test_lgbm[:200])], [min(y_test_lgbm[:200]), max(y_test_lgbm[:200])], color='black', linestyle='--')  # Diagonal line

plt.title('Actual vs Predicted Scatter Plot (first 200 samples)')
plt.xlabel('Actual GHI')
plt.ylabel('Predicted GHI')
plt.legend()
plt.show()

plt.figure(figsize=(12,6))

baseline_error = abs(y_test_lgbm[:200] - y_pred_base[:200])
hybrid_error = abs(y_test_lgbm[:200] - y_pred_hybrid[:200])

plt.plot(baseline_error, label='Baseline Absolute Error', color='blue')
plt.plot(hybrid_error, label='Hybrid Absolute Error', color='red')

plt.title('Absolute Error Comparison (first 200 samples)')
plt.xlabel('Sample index')
plt.ylabel('Absolute Error')
plt.legend()
plt.show()

plt.figure(figsize=(12,6))

plt.plot(y_test_lgbm[:200], label='Actual', color='black', linewidth=2)
plt.plot(y_pred_base[:200], label='Baseline Predictions', color='blue', linestyle='--')
plt.fill_between(range(200), y_test_lgbm[:200], y_pred_base[:200], color='blue', alpha=0.2)

plt.plot(y_pred_hybrid[:200], label='Hybrid Predictions', color='red', linestyle=':')
plt.fill_between(range(200), y_test_lgbm[:200], y_pred_hybrid[:200], color='red', alpha=0.2)

plt.title('Actual vs Predictions with Error Shading')
plt.xlabel('Sample index')
plt.ylabel('GHI')
plt.legend()
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))

plt.subplot(3, 1, 1)
plt.plot(y_test_lgbm[:200], color='black')
plt.title('Actual GHI')
plt.ylabel('GHI')

plt.subplot(3, 1, 2)
plt.plot(y_pred_base[:200], color='blue')
plt.title('Baseline Predictions')
plt.ylabel('GHI')

plt.subplot(3, 1, 3)
plt.plot(y_pred_hybrid[:200], color='red')
plt.title('Hybrid Predictions')
plt.xlabel('Sample index')
plt.ylabel('GHI')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(14, 6))

# Scatter plot for Baseline
plt.subplot(1, 2, 1)
plt.scatter(y_test_lgbm, y_pred_base, alpha=0.3, color='blue', label='Baseline Predictions')
plt.plot([y_test_lgbm.min(), y_test_lgbm.max()], [y_test_lgbm.min(), y_test_lgbm.max()], 'r--')  # Diagonal line
plt.xlabel('Actual GHI')
plt.ylabel('Predicted GHI')
plt.title('Baseline Model: Actual vs Predicted')
plt.legend()
plt.grid(True)

# Scatter plot for Hybrid
plt.subplot(1, 2, 2)
plt.scatter(y_test_lgbm, y_pred_hybrid, alpha=0.3, color='green', label='Hybrid Predictions')
plt.plot([y_test_lgbm.min(), y_test_lgbm.max()], [y_test_lgbm.min(), y_test_lgbm.max()], 'r--')  # Diagonal line
plt.xlabel('Actual GHI')
plt.ylabel('Predicted GHI')
plt.title('Hybrid Model: Actual vs Predicted')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

import numpy as np

plt.figure(figsize=(12, 6))

# Select first 200 samples for clarity
n_samples = 200

# Calculate errors
error_base = np.abs(y_test_lgbm[:n_samples] - y_pred_base[:n_samples])
error_hybrid = np.abs(y_test_lgbm[:n_samples] - y_pred_hybrid[:n_samples])

# Plot actual values
plt.plot(y_test_lgbm[:n_samples], label='Actual', color='black', linewidth=2)

# Plot predictions
plt.plot(y_pred_base[:n_samples], label='Baseline Predictions', color='blue', linestyle='--')
plt.fill_between(range(n_samples),
                 y_pred_base[:n_samples] - error_base,
                 y_pred_base[:n_samples] + error_base,
                 color='blue', alpha=0.2, label='Baseline Error Band')

plt.plot(y_pred_hybrid[:n_samples], label='Hybrid Predictions', color='green', linestyle='-.')
plt.fill_between(range(n_samples),
                 y_pred_hybrid[:n_samples] - error_hybrid,
                 y_pred_hybrid[:n_samples] + error_hybrid,
                 color='green', alpha=0.2, label='Hybrid Error Band')

plt.title('Actual vs Predictions with Error Bands (First 200 samples)')
plt.xlabel('Sample Index')
plt.ylabel('GHI')
plt.legend()
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(14, 6))

# Scatter plot for Baseline (Bright Blue)
plt.subplot(1, 2, 1)
plt.scatter(y_test_lgbm, y_pred_base, alpha=0.5, color='#0072B2', label='Baseline Predictions')  # Strong Blue
plt.plot([y_test_lgbm.min(), y_test_lgbm.max()], [y_test_lgbm.min(), y_test_lgbm.max()], 'r--', linewidth=2)  # Red diagonal line
plt.xlabel('Actual GHI')
plt.ylabel('Predicted GHI')
plt.title('Baseline Model: Actual vs Predicted')
plt.legend()
plt.grid(True)

# Scatter plot for Hybrid (Bright Orange)
plt.subplot(1, 2, 2)
plt.scatter(y_test_lgbm, y_pred_hybrid, alpha=0.5, color='#D55E00', label='Hybrid Predictions')  # Strong Orange
plt.plot([y_test_lgbm.min(), y_test_lgbm.max()], [y_test_lgbm.min(), y_test_lgbm.max()], 'r--', linewidth=2)  # Red diagonal line
plt.xlabel('Actual GHI')
plt.ylabel('Predicted GHI')
plt.title('Hybrid Model: Actual vs Predicted')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

import numpy as np

plt.figure(figsize=(12, 6))

n_samples = 200

error_base = np.abs(y_test_lgbm[:n_samples] - y_pred_base[:n_samples])
error_hybrid = np.abs(y_test_lgbm[:n_samples] - y_pred_hybrid[:n_samples])

# Actual - Black (thick)
plt.plot(y_test_lgbm[:n_samples], label='Actual', color='black', linewidth=3)

# Baseline - Bright Blue solid line with light blue band
plt.plot(y_pred_base[:n_samples], label='Baseline Predictions', color='#0072B2', linestyle='-')
plt.fill_between(range(n_samples),
                 y_pred_base[:n_samples] - error_base,
                 y_pred_base[:n_samples] + error_base,
                 color='#56B4E9', alpha=0.3, label='Baseline Error Band')

# Hybrid - Bright Orange dashed line with light orange band
plt.plot(y_pred_hybrid[:n_samples], label='Hybrid Predictions', color='#D55E00', linestyle='--')
plt.fill_between(range(n_samples),
                 y_pred_hybrid[:n_samples] - error_hybrid,
                 y_pred_hybrid[:n_samples] + error_hybrid,
                 color='#FFA07A', alpha=0.3, label='Hybrid Error Band')

plt.title('Actual vs Predictions with Error Bands (First 200 samples)')
plt.xlabel('Sample Index')
plt.ylabel('GHI')
plt.legend()
plt.grid(True)
plt.savefig("actual vs hubrid.png", dpi=600)
plt.show()



import matplotlib.pyplot as plt

plt.figure(figsize=(14, 6))

# Scatter plot for Baseline (Light Sky Blue)
plt.subplot(1, 2, 1)
plt.scatter(y_test_lgbm, y_pred_base, alpha=0.5, color='#87CEFA', label='Baseline Predictions')
plt.plot([y_test_lgbm.min(), y_test_lgbm.max()], [y_test_lgbm.min(), y_test_lgbm.max()], 'k--', linewidth=2)
plt.xlabel('Actual GHI')
plt.ylabel('Predicted GHI')
plt.title('Baseline Model: Actual vs Predicted')
plt.legend()
plt.grid(True)

# Scatter plot for Hybrid (Dark Slate Blue)
plt.subplot(1, 2, 2)
plt.scatter(y_test_lgbm, y_pred_hybrid, alpha=0.5, color='#2F4F4F', label='Hybrid Predictions')
plt.plot([y_test_lgbm.min(), y_test_lgbm.max()], [y_test_lgbm.min(), y_test_lgbm.max()], 'k--', linewidth=2)
plt.xlabel('Actual GHI')
plt.ylabel('Predicted GHI')
plt.title('Hybrid Model: Actual vs Predicted')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

import numpy as np

plt.figure(figsize=(12, 6))

n_samples = 200

error_base = np.abs(y_test_lgbm[:n_samples] - y_pred_base[:n_samples])
error_hybrid = np.abs(y_test_lgbm[:n_samples] - y_pred_hybrid[:n_samples])

# Actual - Black thick line
plt.plot(y_test_lgbm[:n_samples], label='Actual', color='black', linewidth=3)

# Baseline - Light Sky Blue solid line + light error band
plt.plot(y_pred_base[:n_samples], label='Baseline Predictions', color='#87CEFA', linestyle='-')
plt.fill_between(range(n_samples),
                 y_pred_base[:n_samples] - error_base,
                 y_pred_base[:n_samples] + error_base,
                 color='#B0E0FF', alpha=0.4, label='Baseline Error Band')  # lighter blue

# Hybrid - Dark Slate Blue dashed line + light grey error band
plt.plot(y_pred_hybrid[:n_samples], label='Hybrid Predictions', color='#2F4F4F', linestyle='--')
plt.fill_between(range(n_samples),
                 y_pred_hybrid[:n_samples] - error_hybrid,
                 y_pred_hybrid[:n_samples] + error_hybrid,
                 color='#A9A9A9', alpha=0.3, label='Hybrid Error Band')  # lighter grey

plt.title('Actual vs Predictions with Error Bands (First 200 samples)')
plt.xlabel('Sample Index')
plt.ylabel('GHI')
plt.legend()
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(14, 6))

# Scatter plot for Baseline (Light Sky Blue)
plt.subplot(1, 2, 1)
plt.scatter(y_test_lgbm, y_pred_base, alpha=0.7, s=40, color='#87CEFA', label='Baseline Predictions')
plt.plot([y_test_lgbm.min(), y_test_lgbm.max()], [y_test_lgbm.min(), y_test_lgbm.max()], 'k--', linewidth=3)
plt.xlabel('Actual GHI')
plt.ylabel('Predicted GHI')
plt.title('Baseline Model: Actual vs Predicted')
plt.legend()
plt.grid(True)

# Scatter plot for Hybrid (Dark Slate Blue)
plt.subplot(1, 2, 2)
plt.scatter(y_test_lgbm, y_pred_hybrid, alpha=0.7, s=40, color='#2F4F4F', label='Hybrid Predictions')
plt.plot([y_test_lgbm.min(), y_test_lgbm.max()], [y_test_lgbm.min(), y_test_lgbm.max()], 'k--', linewidth=3)
plt.xlabel('Actual GHI')
plt.ylabel('Predicted GHI')
plt.title('Hybrid Model: Actual vs Predicted')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

import numpy as np

plt.figure(figsize=(12, 6))

n_samples = 200

error_base = np.abs(y_test_lgbm[:n_samples] - y_pred_base[:n_samples])
error_hybrid = np.abs(y_test_lgbm[:n_samples] - y_pred_hybrid[:n_samples])

# Actual - Black thick line
plt.plot(y_test_lgbm[:n_samples], label='Actual', color='black', linewidth=4)

# Baseline - Light Sky Blue solid line + light error band
plt.plot(y_pred_base[:n_samples], label='Baseline Predictions', color='#87CEFA', linestyle='-', linewidth=3)
plt.fill_between(range(n_samples),
                 y_pred_base[:n_samples] - error_base,
                 y_pred_base[:n_samples] + error_base,
                 color='#B0E0FF', alpha=0.4, label='Baseline Error Band')  # lighter blue

# Hybrid - Dark Slate Blue dashed line + light grey error band
plt.plot(y_pred_hybrid[:n_samples], label='Hybrid Predictions', color='#2F4F4F', linestyle='--', linewidth=3)
plt.fill_between(range(n_samples),
                 y_pred_hybrid[:n_samples] - error_hybrid,
                 y_pred_hybrid[:n_samples] + error_hybrid,
                 color='#A9A9A9', alpha=0.3, label='Hybrid Error Band')  # lighter grey

plt.title('Actual vs Predictions with Error Bands (First 200 samples)')
plt.xlabel('Sample Index')
plt.ylabel('GHI')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))

n_samples = 200

error_base = np.abs(y_test_lgbm[:n_samples] - y_pred_base[:n_samples])
error_hybrid = np.abs(y_test_lgbm[:n_samples] - y_pred_hybrid[:n_samples])

# Actual - Black thick line
plt.plot(y_test_lgbm[:n_samples], label='Actual', color='black', linewidth=4)

# Baseline - Green solid line + light green error band
plt.plot(y_pred_base[:n_samples], label='Baseline Predictions', color='green', linestyle='-', linewidth=3)
plt.fill_between(range(n_samples),
                 y_pred_base[:n_samples] - error_base,
                 y_pred_base[:n_samples] + error_base,
                 color='lightgreen', alpha=0.4, label='Baseline Error Band')

# Hybrid - Red dashed line + light red error band
plt.plot(y_pred_hybrid[:n_samples], label='Hybrid Predictions', color='red', linestyle='--', linewidth=3)
plt.fill_between(range(n_samples),
                 y_pred_hybrid[:n_samples] - error_hybrid,
                 y_pred_hybrid[:n_samples] + error_hybrid,
                 color='#ffcccc', alpha=0.4, label='Hybrid Error Band')

plt.title('Actual vs Predictions with Error Bands (First 200 samples)')
plt.xlabel('Sample Index')
plt.ylabel('GHI')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.style as style

# Apply modern clean style
style.use('seaborn-v0_8')

# Parameters
n_samples = 200
scale = 1.5  # To exaggerate error band visibility

# Calculate errors and scale them
error_base = np.abs(y_test_lgbm[:n_samples] - y_pred_base[:n_samples])
error_hybrid = np.abs(y_test_lgbm[:n_samples] - y_pred_hybrid[:n_samples])
error_base_scaled = scale * error_base
error_hybrid_scaled = scale * error_hybrid

# Create figure
plt.figure(figsize=(16, 7))

# --- Plot Error Bands First ---
plt.fill_between(range(n_samples),
                 y_pred_base[:n_samples] - error_base_scaled,
                 y_pred_base[:n_samples] + error_base_scaled,
                 color='lightgreen', alpha=0.4, label='Baseline Error Band')

plt.fill_between(range(n_samples),
                 y_pred_hybrid[:n_samples] - error_hybrid_scaled,
                 y_pred_hybrid[:n_samples] + error_hybrid_scaled,
                 color='#ffcccc', alpha=0.4, label='Hybrid Error Band')

# --- Plot Actual and Predictions ---
plt.plot(y_test_lgbm[:n_samples], label='Actual', color='black', linewidth=3)
plt.plot(y_pred_base[:n_samples], label='Baseline Predictions', color='green', linestyle='-', linewidth=2.5)
plt.plot(y_pred_hybrid[:n_samples], label='Hybrid Predictions', color='red', linestyle='--', linewidth=2.5)

# --- Vertical Event Marker (Optional) ---
plt.axvline(x=100, color='gray', linestyle=':', linewidth=1.5, alpha=0.7)
plt.text(102, max(y_test_lgbm[:n_samples]) * 0.9, 'Event Marker', color='gray', fontsize=10)

# --- Titles and Labels ---
plt.title('Actual vs Predictions with Error Bands', fontsize=16, fontweight='bold')
plt.suptitle('(First 200 Samples of GHI Prediction)', fontsize=12, style='italic', y=0.94)
plt.xlabel('Sample Index', fontsize=13)
plt.ylabel('GHI (Global Horizontal Irradiance)', fontsize=13)

# --- Grid, Legend, and Layout ---
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend(loc='upper right', fontsize=11, frameon=True)
plt.tight_layout()

# --- Save to file (optional) ---
# plt.savefig('ghi_predictions_with_error_bands.png', dpi=300)

# --- Show plot ---
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.style as style

# Apply clean visual style
style.use('seaborn-v0_8')

# Parameters
n_samples = 200
scale = 1.5  # Optional: exaggerate error band width

# Compute errors
error_base = np.abs(y_test_lgbm[:n_samples] - y_pred_base[:n_samples])
error_hybrid = np.abs(y_test_lgbm[:n_samples] - y_pred_hybrid[:n_samples])
error_base_scaled = scale * error_base
error_hybrid_scaled = scale * error_hybrid

# Create 2 vertically stacked subplots
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10), sharex=True, gridspec_kw={'height_ratios': [3, 1]})

# =========================
# 🔷 Top Plot: Actual vs Predictions with Error Bands
# =========================
# Error bands
ax1.fill_between(range(n_samples),
                 y_pred_base[:n_samples] - error_base_scaled,
                 y_pred_base[:n_samples] + error_base_scaled,
                 color='lightgreen', alpha=0.4, label='Baseline Error Band')

ax1.fill_between(range(n_samples),
                 y_pred_hybrid[:n_samples] - error_hybrid_scaled,
                 y_pred_hybrid[:n_samples] + error_hybrid_scaled,
                 color='#ffcccc', alpha=0.4, label='Hybrid Error Band')

# Prediction lines
ax1.plot(y_test_lgbm[:n_samples], label='Actual', color='black', linewidth=3)
ax1.plot(y_pred_base[:n_samples], label='Baseline Predictions', color='green', linewidth=2.5)
ax1.plot(y_pred_hybrid[:n_samples], label='Hybrid Predictions', color='red', linestyle='--', linewidth=2.5)

# Vertical marker
ax1.axvline(x=100, color='gray', linestyle=':', linewidth=1.2)
ax1.text(102, max(y_test_lgbm[:n_samples]) * 0.85, 'Event Marker', color='gray', fontsize=10)

# Labels
ax1.set_title('Actual vs Predictions with Error Bands (First 200 Samples)', fontsize=16, fontweight='bold')
ax1.set_ylabel('GHI (Global Horizontal Irradiance)', fontsize=12)
ax1.grid(True, linestyle='--', alpha=0.5)
ax1.legend(loc='upper right', fontsize=10, frameon=True)

# =========================
# 🔶 Bottom Plot: Absolute Errors
# =========================
ax2.plot(error_base, label='Baseline Error', color='green', linewidth=2)
ax2.plot(error_hybrid, label='Hybrid Error', color='red', linestyle='--', linewidth=2)

ax2.set_title('Prediction Error (Absolute Difference from Actual)', fontsize=14)
ax2.set_xlabel('Sample Index', fontsize=12)
ax2.set_ylabel('Absolute Error', fontsize=12)
ax2.grid(True, linestyle='--', alpha=0.5)
ax2.legend(loc='upper right', fontsize=10, frameon=True)

# Tight layout and optional save
plt.tight_layout()
# plt.savefig("separated_error_plot.png", dpi=300)
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(14, 6))

# Actual - thick black line
plt.plot(y_test_lgbm[:200], label='Actual', color='black', linewidth=3)

# Baseline Prediction - bold blue dashed line + semi-transparent error shade
plt.plot(y_pred_base[:200], label='Baseline Predictions', color='dodgerblue', linestyle='--', linewidth=2.5)
plt.fill_between(range(200), y_test_lgbm[:200], y_pred_base[:200], color='dodgerblue', alpha=0.3)

# Hybrid Prediction - bold red dotted line + semi-transparent error shade
plt.plot(y_pred_hybrid[:200], label='Hybrid Predictions', color='crimson', linestyle=':', linewidth=2.5)
plt.fill_between(range(200), y_test_lgbm[:200], y_pred_hybrid[:200], color='crimson', alpha=0.3)

# Titles and labels
plt.title('Actual vs Predictions with Error Shading', fontsize=16, fontweight='bold')
plt.xlabel('Sample Index', fontsize=12)
plt.ylabel('GHI', fontsize=12)

# Legend and grid
plt.legend(fontsize=10)
plt.grid(True, linestyle='--', alpha=0.6)

plt.tight_layout()
plt.savefig("difference graph.png",dpi=600)
plt.show()

from google.colab import files
files.download("difference graph.png")

import seaborn as sns

feature_imp = model_hybrid.feature_importances_
features = X_train_lgbm.columns
sns.barplot(x=feature_imp, y=features)
plt.title('LightGBM Feature Importance')
plt.show()

whos

print("Length of GHI (after slicing):", len(ghi_values[seq_len:]))
print("Length of LSTM test predictions:", len(lstm_test_preds.flatten()))

# Align ground truth for test portion only
ghi_test_part = ghi_values[-len(lstm_test_preds):]  # Take last portion matching test preds

# Create comparison DataFrame
lstm_check_df = pd.DataFrame({
    'GHI': ghi_test_part,
    'LSTM_Pred': lstm_test_preds.flatten()
})

# Correlation check
corr = lstm_check_df.corr().iloc[0, 1]
print(f"Correlation between GHI and LSTM_Pred: {corr:.4f}")

print("Input shape:", X_lstm.shape)
print("Sample input:", X_lstm[0])

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))
plt.plot(lstm_check_df['GHI'].values[:200], label='Actual GHI', color='black')
plt.plot(lstm_check_df['LSTM_Pred'].values[:200], label='LSTM Prediction', color='green')
plt.title('GHI vs LSTM Prediction (first 200 samples)')
plt.xlabel('Sample Index')
plt.ylabel('GHI')
plt.legend()
plt.grid(True)
plt.show()

# Plot 2: Another slice of 200 samples from test predictions
start = 500  # or choose any other index
end = start + 200

plt.figure(figsize=(10, 5))
plt.plot(range(start, end), ghi_values[seq_len + start: seq_len + end], label='Actual GHI', color='black', linewidth=2)
plt.plot(range(start, end), lstm_test_preds[start:end], label='LSTM Prediction', color='green', linewidth=2)
plt.xlabel('Sample Index')
plt.ylabel('GHI')
plt.title(f'GHI vs LSTM Prediction (samples {start}–{end})')
plt.legend()
plt.grid(True)
plt.show()

features = ['GHI', 'Temperature', 'Relative Humidity', 'Clearsky GHI', 'Wind Speed', 'Pressure']
target_col = 'GHI'  # still predicting GHI
seq_len = 24  # how many time steps back

features = df.columns.tolist()

print(type(df))
print(df.shape)
print(df.columns)

target_col = 'GHI'

# Exclude columns you don’t want as input features
exclude_cols = ['GHI', 'GHI_t', 'datetime']  # GHI is the target, datetime is non-numeric
features = [col for col in df.columns if col not in exclude_cols]

print("Number of features used:", len(features))
print("Features:", features)

df.head()

from sklearn.model_selection import train_test_split

X = df[features]
y = df[target_col]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(df.columns)

import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

pip install --upgrade lightgbm

import lightgbm
print(lightgbm.__version__)

print(df.columns.tolist())

whos

# Drop the 'Datetime' column if it exists
if 'Datetime' in X.columns:
    X = X.drop(columns=['Datetime'])

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

# Drop 'Datetime' column
if 'Datetime' in X.columns:
    X = X.drop(columns=['Datetime'])

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale data
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)  # fit on train only
X_test_scaled = scaler.transform(X_test)        # transform test with same scaler

# Features excluding 'Datetime'
features = [col for col in X.columns if col != 'Datetime']

X_numeric = X[features]  # only numeric columns (or convert categoricals properly)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

X_train, X_test, y_train, y_test = train_test_split(X_numeric, y, test_size=0.2, random_state=42)

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(X_train.dtypes)

X_train_numeric = X_train.select_dtypes(include=['number'])
X_test_numeric = X_test.select_dtypes(include=['number'])

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train_numeric)
X_test_scaled = scaler.transform(X_test_numeric)

# 1. Load data
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import lightgbm as lgb

from sklearn.model_selection import train_test_split
df = pd.read_csv('cleaned_solar_data.csv')

# 2. Generate future GHI if missing
df['GHI_t'] = df['GHI'].shift(-1)
df = df.dropna()

# 3. Define features and target
features = ['Datetime', 'Year', 'Month', 'Day', 'Hour', 'Minute', 'Temperature', 'Clearsky DHI', 'Clearsky DNI', 'Clearsky GHI', 'Dew Point', 'DHI', 'DNI', 'GHI', 'Relative Humidity', 'Solar Zenith Angle', 'Surface Albedo', 'Pressure', 'Wind Speed', 'GHI_t']

target_col = 'GHI_t'

# 4. Prepare X and y
X = df[features].copy()
y = df[target_col].copy()

# 5. Normalize
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train_numeric)  # fit on train data only
X_test_scaled = scaler.transform(X_test_numeric)      # transform test data with the same scaler

# 6. Train-test split
# 1. Split first
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 2. Scale only numeric columns in X_train and X_test
scaler = MinMaxScaler()

# Select numeric columns only (drop non-numeric before scaling)
X_train_numeric = X_train.select_dtypes(include=['number'])
X_test_numeric = X_test.select_dtypes(include=['number'])

# 3. Fit scaler on train, transform train and test
X_train_scaled = scaler.fit_transform(X_train_numeric)
X_test_scaled = scaler.transform(X_test_numeric)



# 7. Train LightGBM model
model = lgb.LGBMRegressor(
    objective='regression',
    metric='rmse',
    n_estimators=500,
    learning_rate=0.05
)
# Select numeric columns only (drop datetime before training and predicting)
X_train_numeric = X_train.select_dtypes(include=['int64', 'float64', 'bool'])
X_test_numeric = X_test.select_dtypes(include=['int64', 'float64', 'bool'])

# Scale numeric columns
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train_numeric)
X_test_scaled = scaler.transform(X_test_numeric)

# Train model on scaled numeric features
model.fit(
    X_train_scaled, y_train,
    eval_set=[(X_test_scaled, y_test)],
    eval_metric='rmse',
    callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(period=100)]
)

# Predict on scaled test numeric features
y_pred_lstm = model.predict(X_test_scaled)

# Evaluate
rmse = np.sqrt(mean_squared_error(y_test, y_pred_lstm))
print(f"LightGBM RMSE: {rmse:.4f}")


# 9. Plot importance
lgb.plot_importance(model, max_num_features=15)
plt.title("Feature Importance - LightGBM")
plt.tight_layout()
plt.show()

print(type(X))
print(X.shape)  # If it is a NumPy array or DataFrame, this shows its dimensions
print(X.head()) # If it is a DataFrame, shows first few rows

from sklearn.preprocessing import MinMaxScaler
import numpy as np
# Drop 'Datetime' column before scaling
X_numeric = X.drop(columns=['Datetime'])

# Then scale only numeric features
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(X_numeric)



# 2. Function to create sequences and target
def create_multivariate_sequences(data, seq_len=24, target_index=7):
    """
    data: scaled numpy array shape (num_samples, num_features)
    seq_len: length of sequence to create
    target_index: index of target feature in data (here GHI is 7th column in your X)

    Returns:
    - X_seq: array of shape (num_sequences, seq_len, num_features)
    - y_seq: array of shape (num_sequences,) targets
    """
    X_seq, y_seq = [], []
    for i in range(len(data) - seq_len):
        X_seq.append(data[i:i+seq_len])
        y_seq.append(data[i+seq_len, target_index])
    return np.array(X_seq), np.array(y_seq)

# 3. Create sequences
seq_len = 24
target_index = X.columns.get_loc('GHI')  # get index of GHI in your features
X_seq, y_seq = create_multivariate_sequences(scaled_data, seq_len, target_index)

print("X_seq shape:", X_seq.shape)  # (num_samples, 24, 22)
print("y_seq shape:", y_seq.shape)  # (num_samples,)

from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# 1. Split data
X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(
    X_seq, y_seq, test_size=0.2, random_state=42
)

# 2. Define LSTM
model = Sequential()
model.add(LSTM(64, input_shape=(24, 19)))  # Corrected to 19 features
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')


# 3. Train
history = model.fit(
    X_train_seq, y_train_seq,
    epochs=10,
    batch_size=64,
    validation_data=(X_test_seq, y_test_seq),
    verbose=1
)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input

model = Sequential()
model.add(Input(shape=(24, 19)))  # use the correct input shape from your data
model.add(LSTM(64))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')

# ✅ Corrected training call
history = model.fit(
    X_train_seq, y_train_seq,
    epochs=10,
    batch_size=64,
    validation_data=(X_test_seq, y_test_seq),
    verbose=1
)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input

model = Sequential()
model.add(Input(shape=(24, 19)))  # Assuming 24 timesteps, 22 features
model.add(Bidirectional(LSTM(64)))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mse')

history = model.fit(
    X_train_seq, y_train_seq,
    epochs=10,
    batch_size=64,
    validation_data=(X_test_seq, y_test_seq),
    verbose=1
)

model = Sequential()
model.add(LSTM(64, return_sequences=True, input_shape=(24, 19)))
model.add(LSTM(32))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
model.fit(X_train_seq, y_train_seq, epochs=10, batch_size=64, validation_data=(X_test_seq, y_test_seq))

from tensorflow.keras.layers import Dropout

model = Sequential()
model.add(LSTM(64, return_sequences=True, input_shape=(24, 19)))
model.add(Dropout(0.2))
model.add(LSTM(32))
model.add(Dropout(0.2))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
model.fit(X_train_seq, y_train_seq, epochs=10, batch_size=64, validation_data=(X_test_seq, y_test_seq))

lstm_preds_test = model.predict(X_test_seq).flatten()

from tensorflow.keras.layers import Layer
import tensorflow.keras.backend as K
import tensorflow as tf

class Attention(Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(name="att_weight", shape=(input_shape[-1], 1),
                                 initializer="normal")
        self.b = self.add_weight(name="att_bias", shape=(input_shape[1], 1),
                                 initializer="zeros")
        super(Attention, self).build(input_shape)

    def call(self, x):
        e = K.tanh(K.dot(x, self.W) + self.b)
        a = K.softmax(e, axis=1)
        output = x * a
        return K.sum(output, axis=1)

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense

# Input shape = (timesteps, features)
input_seq = Input(shape=(24, 19))
lstm_out = LSTM(64, return_sequences=True)(input_seq)
attention = Attention()(lstm_out)
output = Dense(1)(attention)

model = Model(inputs=input_seq, outputs=output)
model.compile(optimizer='adam', loss='mse')
model.summary()

history = model.fit(
    X_train_seq, y_train_seq,
    validation_data=(X_test_seq, y_test_seq),
    epochs=10,
    batch_size=64
)

attn_lstm_preds_test = model.predict(X_test_seq).flatten()

from sklearn.model_selection import train_test_split

# Split sequences and targets into train/test sets
X_train_seq, X_test_seq, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42, shuffle=False)

# Assuming your LSTM model is named 'model'
lstm_train_preds = model.predict(X_train_seq).flatten()
lstm_test_preds = model.predict(X_test_seq).flatten()

# Extract last timestep features from sequences for train and test
X_train_static = X_train_seq[:, -1, :]  # shape: (num_train_samples, num_features)
X_test_static = X_test_seq[:, -1, :]    # shape: (num_test_samples, num_features)

import numpy as np

# Add LSTM predictions as an extra column feature
X_train_lgb = np.hstack([X_train_static, lstm_train_preds.reshape(-1,1)])
X_test_lgb = np.hstack([X_test_static, lstm_test_preds.reshape(-1,1)])

import lightgbm as lgb

lgb_model = lgb.LGBMRegressor(
    objective='regression',
    n_estimators=1000,
    learning_rate=0.05,
    random_state=42
)
lgb_model.fit(
    X_train_lgb, y_train,
    eval_set=[(X_test_lgb, y_test)],
    callbacks=[lgb.early_stopping(stopping_rounds=50)]
)

lgb_preds = lgb_model.predict(X_test_lgb)

from sklearn.metrics import mean_squared_error
import numpy as np

rmse_lgb = np.sqrt(mean_squared_error(y_test, lgb_preds))
print(f"LightGBM RMSE: {rmse_lgb:.4f}")

#2  Generate predictions from LSTM model
y_pred_lstm = model.predict(X_test_seq)  # shape will be (num_samples, 1)

# Flatten to 1D array for metrics
y_pred_lstm = y_pred_lstm.flatten()

#1
def evaluate_model(y_true, y_pred, model_name="Model"):
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    import numpy as np

    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    # Avoid division by zero for MAPE
    nonzero_indices = y_true != 0
    if np.any(nonzero_indices):
        mape = np.mean(np.abs((y_true[nonzero_indices] - y_pred[nonzero_indices]) / y_true[nonzero_indices])) * 100
    else:
        mape = np.nan  # No valid data to compute MAPE

    print(f"--- {model_name} Performance ---")
    print(f"RMSE: {rmse:.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"R^2: {r2:.4f}")
    print(f"MAPE: {mape if not np.isnan(mape) else 'N/A'}%")

    return rmse, mae, r2, mape

# Example train-test split for sequences
split_idx = int(0.8 * len(X_seq))
X_train_seq, X_test_seq = X_seq[:split_idx], X_seq[split_idx:]
y_train, y_test = y_seq[:split_idx], y_seq[split_idx:]

# light 2 Generate LightGBM predictions
y_pred_lgb = lgb_model.predict(X_test_lgb)

# Evaluate LightGBM
evaluate_model(y_test, y_pred_lgb, "LightGBM")

#light 1
def evaluate_model(y_true, y_pred, model_name):
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    import numpy as np

    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    # Safe MAPE calculation
    mask = y_true != 0
    if np.any(mask):
        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100
    else:
        mape = np.nan  # or some indicator that MAPE can't be calculated

    print(f"--- {model_name} Performance ---")
    print(f"RMSE: {rmse:.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"R^2: {r2:.4f}")
    print(f"MAPE: {mape if not np.isnan(mape) else 'N/A'}%")
    print()

    return rmse, mae, r2, mape

hybrid_pred = 0.5 * y_pred_lstm + 0.5 * y_pred_lgb

# Combine predictions
weight_lstm = 0.5
weight_lgb = 0.5

hybrid_pred = weight_lstm * y_pred_lstm + weight_lgb * y_pred_lgb

# Evaluate hybrid
evaluate_model(y_test, hybrid_pred, "Hybrid Model")

import numpy as np

best_rmse = float('inf')
best_w_lstm = 0
best_w_lgb = 0

for w_lstm in np.arange(0, 1.1, 0.1):
    w_lgb = 1 - w_lstm
    hybrid_pred = w_lstm * y_pred_lstm + w_lgb * y_pred_lgb
    rmse = np.sqrt(np.mean((y_test - hybrid_pred)**2))
    if rmse < best_rmse:
        best_rmse = rmse
        best_w_lstm = w_lstm
        best_w_lgb = w_lgb

print(f"Best weights - LSTM: {best_w_lstm}, LightGBM: {best_w_lgb}, RMSE: {best_rmse:.5f}")

y_pred_lstm_test = y_pred_lstm.flatten()  # Now shape is (num_samples,)

y_pred_lgb_test = lgb_model.predict(X_test_lgb)

hybrid_test_pred = 0.1 * y_pred_lstm_test + 0.9 * y_pred_lgb_test

evaluate_model(y_test, hybrid_test_pred, "Hybrid")

best_rmse = float('inf')
best_weights = (0, 0)
best_metrics = None

def safe_mape(y_true, y_pred, epsilon=1e-3):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    mask = np.abs(y_true) > epsilon  # mask out near-zero actuals
    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100

for w in np.arange(0.0, 1.1, 0.1):
    w = round(w, 1)
    hybrid_pred = w * y_pred_lstm_test.flatten() + (1 - w) * y_pred_lgb_test.flatten()

    rmse = np.sqrt(mean_squared_error(y_test, hybrid_pred))
    mae = mean_absolute_error(y_test, hybrid_pred)
    r2 = r2_score(y_test, hybrid_pred)
    mape = np.mean(np.abs((y_test - hybrid_pred) / np.maximum(y_test, 1e-6))) * 100  # avoid division by 0
    mape = safe_mape(y_test, hybrid_pred)

    if rmse < best_rmse:
        best_rmse = rmse
        best_weights = (w, 1 - w)
        best_metrics = (rmse, mae, r2, mape)

    print(f"Weights: LSTM={w}, LightGBM={1-w} --> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, MAPE: {mape:.2f}%")

print("\n✅ Best Hybrid Weights Found:")
print(f"LSTM: {best_weights[0]}, LightGBM: {best_weights[1]}")
print(f"Metrics -> RMSE: {best_metrics[0]:.4f}, MAE: {best_metrics[1]:.4f}, R²: {best_metrics[2]:.4f}, MAPE: {best_metrics[3]:.2f}%")

def safe_mape(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    mask = y_true > 1e-2  # ignore near-zero targets
    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100

mape = safe_mape(y_test, hybrid_pred)

def safe_mape(y_true, y_pred, epsilon=1e-3):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    mask = np.abs(y_true) > epsilon  # avoid divide by zero
    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100

mape = safe_mape(y_test, hybrid_pred)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Replace these with your actual model predictions
# y_pred_lstm_test and y_pred_lgb_test should be defined earlier
# y_test should be your actual test labels

lstm_weights = np.arange(0.0, 1.1, 0.1)
rmse_scores = []
mae_scores = []
r2_scores = []
mape_scores = []

for w_lstm in lstm_weights:
    w_lgb = 1.0 - w_lstm
    hybrid_pred = w_lstm * y_pred_lstm_test + w_lgb * y_pred_lgb_test

    rmse = np.sqrt(mean_squared_error(y_test, hybrid_pred))
    mae = mean_absolute_error(y_test, hybrid_pred)
    r2 = r2_score(y_test, hybrid_pred)
    mape = np.mean(np.abs((y_test - hybrid_pred) / np.maximum(y_test, 1e-6))) * 100  # avoids division by zero

    rmse_scores.append(rmse)
    mae_scores.append(mae)
    r2_scores.append(r2)
    mape_scores.append(mape)

    print(f"Weights: LSTM={w_lstm:.1f}, LightGBM={w_lgb:.1f} --> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, MAPE: {mape:.2f}%")

# Plotting the comparison
plt.figure(figsize=(14, 10))

plt.subplot(2, 2, 1)
plt.plot(lstm_weights, rmse_scores, marker='o', label='RMSE')
plt.title('RMSE vs LSTM Weight')
plt.xlabel('LSTM Weight')
plt.ylabel('RMSE')
plt.grid(True)

plt.subplot(2, 2, 2)
plt.plot(lstm_weights, mae_scores, marker='o', label='MAE', color='orange')
plt.title('MAE vs LSTM Weight')
plt.xlabel('LSTM Weight')
plt.ylabel('MAE')
plt.grid(True)

plt.subplot(2, 2, 3)
plt.plot(lstm_weights, r2_scores, marker='o', label='R²', color='green')
plt.title('R² vs LSTM Weight')
plt.xlabel('LSTM Weight')
plt.ylabel('R² Score')
plt.grid(True)

plt.subplot(2, 2, 4)
plt.plot(lstm_weights, mape_scores, marker='o', label='MAPE', color='red')
plt.title('MAPE vs LSTM Weight')
plt.xlabel('LSTM Weight')
plt.ylabel('MAPE (%)')
plt.grid(True)

plt.tight_layout()
plt.savefig("metrics vs lstm weight.png",dpi=600)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Hybrid weight combinations
lstm_weights = np.arange(0.0, 1.1, 0.1)
rmse_scores, mae_scores, r2_scores, mape_scores = [], [], [], []

# Calculate hybrid metrics
for w_lstm in lstm_weights:
    w_lgb = 1.0 - w_lstm
    hybrid_pred = w_lstm * y_pred_lstm_test + w_lgb * y_pred_lgb_test

    rmse = np.sqrt(mean_squared_error(y_test, hybrid_pred))
    mae = mean_absolute_error(y_test, hybrid_pred)
    r2 = r2_score(y_test, hybrid_pred)
    mape = np.mean(np.abs((y_test - hybrid_pred) / np.maximum(y_test, 1e-6))) * 100

    rmse_scores.append(rmse)
    mae_scores.append(mae)
    r2_scores.append(r2)
    mape_scores.append(mape)

    print(f"Weights: LSTM={w_lstm:.1f}, LightGBM={w_lgb:.1f} --> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, MAPE: {mape:.2f}%")

# Set white background
plt.style.use('default')
fig = plt.figure(figsize=(14, 10), facecolor='white')

# Subplots
plt.subplot(2, 2, 1)
plt.plot(lstm_weights, rmse_scores, marker='o', label='RMSE', color='blue')
plt.title('RMSE vs LSTM Weight')
plt.xlabel('LSTM Weight')
plt.ylabel('RMSE')
plt.grid(True)
plt.gca().set_facecolor('white')

plt.subplot(2, 2, 2)
plt.plot(lstm_weights, mae_scores, marker='o', label='MAE', color='orange')
plt.title('MAE vs LSTM Weight')
plt.xlabel('LSTM Weight')
plt.ylabel('MAE')
plt.grid(True)
plt.gca().set_facecolor('white')

plt.subplot(2, 2, 3)
plt.plot(lstm_weights, r2_scores, marker='o', label='R²', color='green')
plt.title('R² vs LSTM Weight')
plt.xlabel('LSTM Weight')
plt.ylabel('R² Score')
plt.grid(True)
plt.gca().set_facecolor('white')

plt.subplot(2, 2, 4)
plt.plot(lstm_weights, mape_scores, marker='o', label='MAPE', color='red')
plt.title('MAPE vs LSTM Weight')
plt.xlabel('LSTM Weight')
plt.ylabel('MAPE (%)')
plt.grid(True)
plt.gca().set_facecolor('white')

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Hybrid weight combinations
lstm_weights = np.arange(0.0, 1.1, 0.1)
rmse_scores, mae_scores, r2_scores, mape_scores = [], [], [], []

# Calculate hybrid metrics
for w_lstm in lstm_weights:
    w_lgb = 1.0 - w_lstm
    hybrid_pred = w_lstm * y_pred_lstm_test + w_lgb * y_pred_lgb_test

    rmse = np.sqrt(mean_squared_error(y_test, hybrid_pred))
    mae = mean_absolute_error(y_test, hybrid_pred)
    r2 = r2_score(y_test, hybrid_pred)
    mape = np.mean(np.abs((y_test - hybrid_pred) / np.maximum(y_test, 1e-6))) * 100

    rmse_scores.append(rmse)
    mae_scores.append(mae)
    r2_scores.append(r2)
    mape_scores.append(mape)

    print(f"Weights: LSTM={w_lstm:.1f}, LightGBM={w_lgb:.1f} --> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, MAPE: {mape:.2f}%")

# Set white background
plt.style.use('default')
fig = plt.figure(figsize=(15, 12), facecolor='white')

# Subplots with white facecolor and more spacing
plt.subplot(2, 2, 1)
plt.plot(lstm_weights, rmse_scores, marker='o', color='blue')
plt.title('RMSE vs LSTM Weight')
plt.xlabel('LSTM Weight')
plt.ylabel('RMSE')
plt.grid(True)
plt.gca().set_facecolor('white')

plt.subplot(2, 2, 2)
plt.plot(lstm_weights, mae_scores, marker='o', color='orange')
plt.title('MAE vs LSTM Weight')
plt.xlabel('LSTM Weight')
plt.ylabel('MAE')
plt.grid(True)
plt.gca().set_facecolor('white')

plt.subplot(2, 2, 3)
plt.plot(lstm_weights, r2_scores, marker='o', color='green')
plt.title('R² vs LSTM Weight')
plt.xlabel('LSTM Weight')
plt.ylabel('R² Score')
plt.grid(True)
plt.gca().set_facecolor('white')

plt.subplot(2, 2, 4)
plt.plot(lstm_weights, mape_scores, marker='o', color='red')
plt.title('MAPE vs LSTM Weight')
plt.xlabel('LSTM Weight')
plt.ylabel('MAPE (%)')
plt.grid(True)
plt.gca().set_facecolor('white')

# Add spacing between plots
plt.tight_layout(pad=4.0, w_pad=3.0, h_pad=3.0)
plt.savefig("metrics vs lstm weight.png",dpi=600)

plt.show()

from google.colab import files
files.download("metrics vs lstm weight.png")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Hybrid weight combinations
lstm_weights = np.arange(0.0, 1.1, 0.1)
rmse_scores, mae_scores, r2_scores, mape_scores = [], [], [], []

# Calculate hybrid metrics
for w_lstm in lstm_weights:
    w_lgb = 1.0 - w_lstm
    hybrid_pred = w_lstm * y_pred_lstm_test + w_lgb * y_pred_lgb_test

    rmse = np.sqrt(mean_squared_error(y_test, hybrid_pred))
    mae = mean_absolute_error(y_test, hybrid_pred)
    r2 = r2_score(y_test, hybrid_pred)
    mape = np.mean(np.abs((y_test - hybrid_pred) / np.maximum(y_test, 1e-6))) * 100

    rmse_scores.append(rmse)
    mae_scores.append(mae)
    r2_scores.append(r2)
    mape_scores.append(mape)

    print(f"Weights: LSTM={w_lstm:.1f}, LightGBM={w_lgb:.1f} --> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, MAPE: {mape:.2f}%")

plt.style.use('default')
fig = plt.figure(figsize=(15, 12), facecolor='white')

def annotate_best(ax, x_vals, y_vals, best_idx, is_max=False):
    x_best = x_vals[best_idx]
    y_best = y_vals[best_idx]
    # Black star for highlight
    ax.plot(x_best, y_best, marker='*', color='black', markersize=15)
    ax.annotate(f'{y_best:.4f}', xy=(x_best, y_best), xytext=(5, 10),
                textcoords='offset points', color='black', fontsize=12, weight='bold')

# Define gray shades for each plot line for contrast
colors = ['#555555', '#777777', '#999999', '#BBBBBB']

# RMSE plot (minimize)
ax1 = plt.subplot(2, 2, 1)
ax1.plot(lstm_weights, rmse_scores, marker='o', color=colors[0])
ax1.set_title('RMSE vs LSTM Weight')
ax1.set_xlabel('LSTM Weight')
ax1.set_ylabel('RMSE')
ax1.grid(True, linestyle='--', alpha=0.5)
ax1.set_facecolor('white')
best_rmse_idx = np.argmin(rmse_scores)
annotate_best(ax1, lstm_weights, rmse_scores, best_rmse_idx)

# MAE plot (minimize)
ax2 = plt.subplot(2, 2, 2)
ax2.plot(lstm_weights, mae_scores, marker='o', color=colors[1])
ax2.set_title('MAE vs LSTM Weight')
ax2.set_xlabel('LSTM Weight')
ax2.set_ylabel('MAE')
ax2.grid(True, linestyle='--', alpha=0.5)
ax2.set_facecolor('white')
best_mae_idx = np.argmin(mae_scores)
annotate_best(ax2, lstm_weights, mae_scores, best_mae_idx)

# R² plot (maximize)
ax3 = plt.subplot(2, 2, 3)
ax3.plot(lstm_weights, r2_scores, marker='o', color=colors[2])
ax3.set_title('R² vs LSTM Weight')
ax3.set_xlabel('LSTM Weight')
ax3.set_ylabel('R² Score')
ax3.grid(True, linestyle='--', alpha=0.5)
ax3.set_facecolor('white')
best_r2_idx = np.argmax(r2_scores)
annotate_best(ax3, lstm_weights, r2_scores, best_r2_idx, is_max=True)

# MAPE plot (minimize)
ax4 = plt.subplot(2, 2, 4)
ax4.plot(lstm_weights, mape_scores, marker='o', color=colors[3])
ax4.set_title('MAPE vs LSTM Weight')
ax4.set_xlabel('LSTM Weight')
ax4.set_ylabel('MAPE (%)')
ax4.grid(True, linestyle='--', alpha=0.5)
ax4.set_facecolor('white')
best_mape_idx = np.argmin(mape_scores)
annotate_best(ax4, lstm_weights, mape_scores, best_mape_idx)

plt.tight_layout(pad=4.0, w_pad=3.0, h_pad=3.0)
plt.savefig("metrics_vs_lstm_weight_monochrome.png", dpi=600)

plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Hybrid weight combinations
lstm_weights = np.arange(0.0, 1.1, 0.1)
rmse_scores, mae_scores, r2_scores, mape_scores = [], [], [], []

# Calculate hybrid metrics
for w_lstm in lstm_weights:
    w_lgb = 1.0 - w_lstm
    hybrid_pred = w_lstm * y_pred_lstm_test + w_lgb * y_pred_lgb_test

    rmse = np.sqrt(mean_squared_error(y_test, hybrid_pred))
    mae = mean_absolute_error(y_test, hybrid_pred)
    r2 = r2_score(y_test, hybrid_pred)
    mape = np.mean(np.abs((y_test - hybrid_pred) / np.maximum(y_test, 1e-6))) * 100

    rmse_scores.append(rmse)
    mae_scores.append(mae)
    r2_scores.append(r2)
    mape_scores.append(mape)

    print(f"Weights: LSTM={w_lstm:.1f}, LightGBM={w_lgb:.1f} --> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, MAPE: {mape:.2f}%")

# Set white background
plt.style.use('default')
fig = plt.figure(figsize=(15, 12), facecolor='white')

def annotate_best(ax, x_vals, y_vals, best_idx, is_max=False):
    x_best = x_vals[best_idx]
    y_best = y_vals[best_idx]
    ax.plot(x_best, y_best, 'r*', markersize=15)
    ax.annotate(f'{y_best:.4f}', xy=(x_best, y_best), xytext=(5, 10),
                textcoords='offset points', color='red', fontsize=12, weight='bold')

# RMSE plot (minimize)
ax1 = plt.subplot(2, 2, 1)
ax1.plot(lstm_weights, rmse_scores, marker='o', color='blue')
ax1.set_title('RMSE vs LSTM Weight')
ax1.set_xlabel('LSTM Weight')
ax1.set_ylabel('RMSE')
ax1.grid(True)
ax1.set_facecolor('white')
best_rmse_idx = np.argmin(rmse_scores)
annotate_best(ax1, lstm_weights, rmse_scores, best_rmse_idx)

# MAE plot (minimize)
ax2 = plt.subplot(2, 2, 2)
ax2.plot(lstm_weights, mae_scores, marker='o', color='orange')
ax2.set_title('MAE vs LSTM Weight')
ax2.set_xlabel('LSTM Weight')
ax2.set_ylabel('MAE')
ax2.grid(True)
ax2.set_facecolor('white')
best_mae_idx = np.argmin(mae_scores)
annotate_best(ax2, lstm_weights, mae_scores, best_mae_idx)

# R² plot (maximize)
ax3 = plt.subplot(2, 2, 3)
ax3.plot(lstm_weights, r2_scores, marker='o', color='green')
ax3.set_title('R² vs LSTM Weight')
ax3.set_xlabel('LSTM Weight')
ax3.set_ylabel('R² Score')
ax3.grid(True)
ax3.set_facecolor('white')
best_r2_idx = np.argmax(r2_scores)
annotate_best(ax3, lstm_weights, r2_scores, best_r2_idx, is_max=True)

# MAPE plot (minimize)
ax4 = plt.subplot(2, 2, 4)
ax4.plot(lstm_weights, mape_scores, marker='o', color='red')
ax4.set_title('MAPE vs LSTM Weight')
ax4.set_xlabel('LSTM Weight')
ax4.set_ylabel('MAPE (%)')
ax4.grid(True)
ax4.set_facecolor('white')
best_mape_idx = np.argmin(mape_scores)
annotate_best(ax4, lstm_weights, mape_scores, best_mape_idx)

# Add spacing between plots
plt.tight_layout(pad=4.0, w_pad=3.0, h_pad=3.0)
plt.savefig("metrics_vs_lstm_weight_colour.png", dpi=600)

plt.show()

from google.colab import files
files.download("metrics_vs_lstm_weight_colour.png")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Hybrid weight combinations
lstm_weights = np.arange(0.0, 1.1, 0.1)
rmse_scores, mae_scores, r2_scores, mape_scores = [], [], [], []

# Calculate hybrid metrics
for w_lstm in lstm_weights:
    w_lgb = 1.0 - w_lstm
    hybrid_pred = w_lstm * y_pred_lstm_test + w_lgb * y_pred_lgb_test

    rmse = np.sqrt(mean_squared_error(y_test, hybrid_pred))
    mae = mean_absolute_error(y_test, hybrid_pred)
    r2 = r2_score(y_test, hybrid_pred)
    mape = np.mean(np.abs((y_test - hybrid_pred) / np.maximum(y_test, 1e-6))) * 100

    rmse_scores.append(rmse)
    mae_scores.append(mae)
    r2_scores.append(r2)
    mape_scores.append(mape)

    print(f"Weights: LSTM={w_lstm:.1f}, LightGBM={w_lgb:.1f} --> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, MAPE: {mape:.2f}%")

plt.style.use('default')
fig = plt.figure(figsize=(15, 12), facecolor='white')

def annotate_best(ax, x_vals, y_vals, best_idx, is_max=False, text_color='black'):
    x_best = x_vals[best_idx]
    y_best = y_vals[best_idx]
    ax.plot(x_best, y_best, marker='*', color='black', markersize=15)
    ax.annotate(f'{y_best:.4f}', xy=(x_best, y_best), xytext=(5, 10),
                textcoords='offset points', color=text_color, fontsize=12, weight='bold')

# Gray shades for line colors
colors = ['#555555', '#777777', '#999999', '#BBBBBB']

# RMSE plot (minimize)
ax1 = plt.subplot(2, 2, 1)
ax1.plot(lstm_weights, rmse_scores, marker='o', color=colors[0])
ax1.set_title('RMSE vs LSTM Weight')
ax1.set_xlabel('LSTM Weight')
ax1.set_ylabel('RMSE')
ax1.grid(True, linestyle='--', alpha=0.5)
ax1.set_facecolor('white')
best_rmse_idx = np.argmin(rmse_scores)
annotate_best(ax1, lstm_weights, rmse_scores, best_rmse_idx)

# MAE plot (minimize)
ax2 = plt.subplot(2, 2, 2)
ax2.plot(lstm_weights, mae_scores, marker='o', color=colors[1])
ax2.set_title('MAE vs LSTM Weight')
ax2.set_xlabel('LSTM Weight')
ax2.set_ylabel('MAE')
ax2.grid(True, linestyle='--', alpha=0.5)
ax2.set_facecolor('white')
best_mae_idx = np.argmin(mae_scores)
annotate_best(ax2, lstm_weights, mae_scores, best_mae_idx)

# R² plot (maximize)
ax3 = plt.subplot(2, 2, 3)
ax3.plot(lstm_weights, r2_scores, marker='o', color=colors[2])
ax3.set_title('R² vs LSTM Weight')
ax3.set_xlabel('LSTM Weight')
ax3.set_ylabel('R² Score')
ax3.grid(True, linestyle='--', alpha=0.5)
ax3.set_facecolor('white')
best_r2_idx = np.argmax(r2_scores)
annotate_best(ax3, lstm_weights, r2_scores, best_r2_idx, is_max=True)

# MAPE plot (minimize) — annotation in dark red for visibility
ax4 = plt.subplot(2, 2, 4)
ax4.plot(lstm_weights, mape_scores, marker='o', color=colors[3])
ax4.set_title('MAPE vs LSTM Weight')
ax4.set_xlabel('LSTM Weight')
ax4.set_ylabel('MAPE (%)')
ax4.grid(True, linestyle='--', alpha=0.5)
ax4.set_facecolor('white')
best_mape_idx = np.argmin(mape_scores)
annotate_best(ax4, lstm_weights, mape_scores, best_mape_idx, text_color='darkred')

plt.tight_layout(pad=4.0, w_pad=3.0, h_pad=3.0)
plt.savefig("metrics_vs_lstm_weight_monochrome.png", dpi=600)

plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Hybrid weight combinations
lstm_weights = np.arange(0.0, 1.1, 0.1)
rmse_scores, mae_scores, r2_scores, mape_scores = [], [], [], []

# Calculate hybrid metrics
for w_lstm in lstm_weights:
    w_lgb = 1.0 - w_lstm
    hybrid_pred = w_lstm * y_pred_lstm_test + w_lgb * y_pred_lgb_test

    rmse = np.sqrt(mean_squared_error(y_test, hybrid_pred))
    mae = mean_absolute_error(y_test, hybrid_pred)
    r2 = r2_score(y_test, hybrid_pred)
    mape = np.mean(np.abs((y_test - hybrid_pred) / np.maximum(y_test, 1e-6))) * 100

    rmse_scores.append(rmse)
    mae_scores.append(mae)
    r2_scores.append(r2)
    mape_scores.append(mape)

    print(f"Weights: LSTM={w_lstm:.1f}, LightGBM={w_lgb:.1f} --> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, MAPE: {mape:.2f}%")

plt.style.use('default')
fig = plt.figure(figsize=(15, 12), facecolor='white')

def annotate_best(ax, x_vals, y_vals, best_idx, is_max=False, text_color='black'):
    x_best = x_vals[best_idx]
    y_best = y_vals[best_idx]
    ax.plot(x_best, y_best, marker='*', color=text_color, markersize=15)
    ax.annotate(f'{y_best:.4f}', xy=(x_best, y_best), xytext=(5, 10),
                textcoords='offset points', color=text_color, fontsize=12, weight='bold')

# Colors for each metric plot
colors = ['blue', 'orange', 'green', 'purple']

# RMSE plot (minimize)
ax1 = plt.subplot(2, 2, 1)
ax1.plot(lstm_weights, rmse_scores, marker='o', color=colors[0])
ax1.set_title('RMSE vs LSTM Weight')
ax1.set_xlabel('LSTM Weight')
ax1.set_ylabel('RMSE')
ax1.grid(True)
ax1.set_facecolor('white')
best_rmse_idx = np.argmin(rmse_scores)
annotate_best(ax1, lstm_weights, rmse_scores, best_rmse_idx, text_color=colors[0])

# MAE plot (minimize)
ax2 = plt.subplot(2, 2, 2)
ax2.plot(lstm_weights, mae_scores, marker='o', color=colors[1])
ax2.set_title('MAE vs LSTM Weight')
ax2.set_xlabel('LSTM Weight')
ax2.set_ylabel('MAE')
ax2.grid(True)
ax2.set_facecolor('white')
best_mae_idx = np.argmin(mae_scores)
annotate_best(ax2, lstm_weights, mae_scores, best_mae_idx, text_color=colors[1])

# R² plot (maximize)
ax3 = plt.subplot(2, 2, 3)
ax3.plot(lstm_weights, r2_scores, marker='o', color=colors[2])
ax3.set_title('R² vs LSTM Weight')
ax3.set_xlabel('LSTM Weight')
ax3.set_ylabel('R² Score')
ax3.grid(True)
ax3.set_facecolor('white')
best_r2_idx = np.argmax(r2_scores)
annotate_best(ax3, lstm_weights, r2_scores, best_r2_idx, is_max=True, text_color=colors[2])

# MAPE plot (minimize) — changed color to purple
ax4 = plt.subplot(2, 2, 4)
ax4.plot(lstm_weights, mape_scores, marker='o', color=colors[3])
ax4.set_title('MAPE vs LSTM Weight')
ax4.set_xlabel('LSTM Weight')
ax4.set_ylabel('MAPE (%)')
ax4.grid(True)
ax4.set_facecolor('white')
best_mape_idx = np.argmin(mape_scores)
annotate_best(ax4, lstm_weights, mape_scores, best_mape_idx, text_color=colors[3])

plt.tight_layout(pad=4.0, w_pad=3.0, h_pad=3.0)
plt.savefig("metrics_vs_lstm_weight_colored.png", dpi=600)

plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Hybrid weight combinations
lstm_weights = np.arange(0.0, 1.1, 0.1)
rmse_scores, mae_scores, r2_scores, mape_scores = [], [], [], []

# Calculate hybrid metrics
for w_lstm in lstm_weights:
    w_lgb = 1.0 - w_lstm
    hybrid_pred = w_lstm * y_pred_lstm_test + w_lgb * y_pred_lgb_test

    rmse = np.sqrt(mean_squared_error(y_test, hybrid_pred))
    mae = mean_absolute_error(y_test, hybrid_pred)
    r2 = r2_score(y_test, hybrid_pred)
    mape = np.mean(np.abs((y_test - hybrid_pred) / np.maximum(y_test, 1e-6))) * 100

    rmse_scores.append(rmse)
    mae_scores.append(mae)
    r2_scores.append(r2)
    mape_scores.append(mape)

    print(f"Weights: LSTM={w_lstm:.1f}, LightGBM={w_lgb:.1f} --> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, MAPE: {mape:.2f}%")

plt.style.use('default')
fig = plt.figure(figsize=(15, 12), facecolor='white')

def annotate_best(ax, x_vals, y_vals, best_idx, is_max=False, text_color='black'):
    x_best = x_vals[best_idx]
    y_best = y_vals[best_idx]
    # Star marker color fixed as red
    ax.plot(x_best, y_best, marker='*', color='red', markersize=15)
    ax.annotate(f'{y_best:.4f}', xy=(x_best, y_best), xytext=(5, 10),
                textcoords='offset points', color=text_color, fontsize=12, weight='bold')

# Different colors for each plot line
colors = ['blue', 'orange', 'green', 'purple']

# RMSE plot (minimize)
ax1 = plt.subplot(2, 2, 1)
ax1.plot(lstm_weights, rmse_scores, marker='o', color=colors[0])
ax1.set_title('RMSE vs LSTM Weight')
ax1.set_xlabel('LSTM Weight')
ax1.set_ylabel('RMSE')
ax1.grid(True)
ax1.set_facecolor('white')
best_rmse_idx = np.argmin(rmse_scores)
annotate_best(ax1, lstm_weights, rmse_scores, best_rmse_idx, text_color=colors[0])

# MAE plot (minimize)
ax2 = plt.subplot(2, 2, 2)
ax2.plot(lstm_weights, mae_scores, marker='o', color=colors[1])
ax2.set_title('MAE vs LSTM Weight')
ax2.set_xlabel('LSTM Weight')
ax2.set_ylabel('MAE')
ax2.grid(True)
ax2.set_facecolor('white')
best_mae_idx = np.argmin(mae_scores)
annotate_best(ax2, lstm_weights, mae_scores, best_mae_idx, text_color=colors[1])

# R² plot (maximize)
ax3 = plt.subplot(2, 2, 3)
ax3.plot(lstm_weights, r2_scores, marker='o', color=colors[2])
ax3.set_title('R² vs LSTM Weight')
ax3.set_xlabel('LSTM Weight')
ax3.set_ylabel('R² Score')
ax3.grid(True)
ax3.set_facecolor('white')
best_r2_idx = np.argmax(r2_scores)
annotate_best(ax3, lstm_weights, r2_scores, best_r2_idx, is_max=True, text_color=colors[2])

# MAPE plot (minimize)
ax4 = plt.subplot(2, 2, 4)
ax4.plot(lstm_weights, mape_scores, marker='o', color=colors[3])
ax4.set_title('MAPE vs LSTM Weight')
ax4.set_xlabel('LSTM Weight')
ax4.set_ylabel('MAPE (%)')
ax4.grid(True)
ax4.set_facecolor('white')
best_mape_idx = np.argmin(mape_scores)
annotate_best(ax4, lstm_weights, mape_scores, best_mape_idx, text_color=colors[3])

plt.tight_layout(pad=4.0, w_pad=3.0, h_pad=3.0)
plt.savefig("metrics_vs_lstm_weight_color_red_star.png", dpi=600)

plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Hybrid weight combinations
lstm_weights = np.arange(0.0, 1.1, 0.1)
rmse_scores, mae_scores, r2_scores, mape_scores = [], [], [], []

# Calculate hybrid metrics
for w_lstm in lstm_weights:
    w_lgb = 1.0 - w_lstm
    hybrid_pred = w_lstm * y_pred_lstm_test + w_lgb * y_pred_lgb_test

    rmse = np.sqrt(mean_squared_error(y_test, hybrid_pred))
    mae = mean_absolute_error(y_test, hybrid_pred)
    r2 = r2_score(y_test, hybrid_pred)
    mape = np.mean(np.abs((y_test - hybrid_pred) / np.maximum(y_test, 1e-6))) * 100

    rmse_scores.append(rmse)
    mae_scores.append(mae)
    r2_scores.append(r2)
    mape_scores.append(mape)

    print(f"Weights: LSTM={w_lstm:.1f}, LightGBM={w_lgb:.1f} --> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, MAPE: {mape:.2f}%")

plt.style.use('default')
fig = plt.figure(figsize=(15, 12), facecolor='white')

def annotate_best(ax, x_vals, y_vals, best_idx, is_max=False, text_color='black'):
    x_best = x_vals[best_idx]
    y_best = y_vals[best_idx]
    # Star marker color fixed as red
    ax.plot(x_best, y_best, marker='*', color='red', markersize=15)
    ax.annotate(f'{y_best:.4f}', xy=(x_best, y_best), xytext=(5, 10),
                textcoords='offset points', color=text_color, fontsize=12, weight='bold')

# Colors for the lines only
line_colors = ['blue', 'orange', 'green', 'purple']

# RMSE plot (minimize)
ax1 = plt.subplot(2, 2, 1)
ax1.plot(lstm_weights, rmse_scores, color=line_colors[0], marker='o', markerfacecolor='red', markeredgecolor='red')
ax1.set_title('RMSE vs LSTM Weight')
ax1.set_xlabel('LSTM Weight')
ax1.set_ylabel('RMSE')
ax1.grid(True)
ax1.set_facecolor('white')
best_rmse_idx = np.argmin(rmse_scores)
annotate_best(ax1, lstm_weights, rmse_scores, best_rmse_idx, text_color=line_colors[0])

# MAE plot (minimize)
ax2 = plt.subplot(2, 2, 2)
ax2.plot(lstm_weights, mae_scores, color=line_colors[1], marker='o', markerfacecolor='red', markeredgecolor='red')
ax2.set_title('MAE vs LSTM Weight')
ax2.set_xlabel('LSTM Weight')
ax2.set_ylabel('MAE')
ax2.grid(True)
ax2.set_facecolor('white')
best_mae_idx = np.argmin(mae_scores)
annotate_best(ax2, lstm_weights, mae_scores, best_mae_idx, text_color=line_colors[1])

# R² plot (maximize)
ax3 = plt.subplot(2, 2, 3)
ax3.plot(lstm_weights, r2_scores, color=line_colors[2], marker='o', markerfacecolor='red', markeredgecolor='red')
ax3.set_title('R² vs LSTM Weight')
ax3.set_xlabel('LSTM Weight')
ax3.set_ylabel('R² Score')
ax3.grid(True)
ax3.set_facecolor('white')
best_r2_idx = np.argmax(r2_scores)
annotate_best(ax3, lstm_weights, r2_scores, best_r2_idx, is_max=True, text_color=line_colors[2])

# MAPE plot (minimize)
ax4 = plt.subplot(2, 2, 4)
ax4.plot(lstm_weights, mape_scores, color=line_colors[3], marker='o', markerfacecolor='red', markeredgecolor='red')
ax4.set_title('MAPE vs LSTM Weight')
ax4.set_xlabel('LSTM Weight')
ax4.set_ylabel('MAPE (%)')
ax4.grid(True)
ax4.set_facecolor('white')
best_mape_idx = np.argmin(mape_scores)
annotate_best(ax4, lstm_weights, mape_scores, best_mape_idx, text_color=line_colors[3])

plt.tight_layout(pad=4.0, w_pad=3.0, h_pad=3.0)
plt.savefig("metrics_vs_lstm_weight_red_points.png", dpi=600)

plt.show()



import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Dummy data placeholders for testing; replace these with your actual arrays
# y_test = ...
# y_pred_lstm_test = ...
# y_pred_lgb_test = ...

# Hybrid weight combinations
lstm_weights = np.arange(0.0, 1.1, 0.1)
rmse_scores, mae_scores, r2_scores, mape_scores = [], [], [], []

# Calculate hybrid metrics
for w_lstm in lstm_weights:
    w_lgb = 1.0 - w_lstm
    hybrid_pred = w_lstm * y_pred_lstm_test + w_lgb * y_pred_lgb_test

    rmse = np.sqrt(mean_squared_error(y_test, hybrid_pred))
    mae = mean_absolute_error(y_test, hybrid_pred)
    r2 = r2_score(y_test, hybrid_pred)
    mape = np.mean(np.abs((y_test - hybrid_pred) / np.maximum(y_test, 1e-6))) * 100

    rmse_scores.append(rmse)
    mae_scores.append(mae)
    r2_scores.append(r2)
    mape_scores.append(mape)

    print(f"Weights: LSTM={w_lstm:.1f}, LightGBM={w_lgb:.1f} --> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, MAPE: {mape:.2f}%")

plt.style.use('default')
fig = plt.figure(figsize=(15, 12), facecolor='white')

def annotate_points_and_best(ax, x_vals, y_vals, best_idx, line_color):
    # Plot point numbers next to each marker
    for i, (x, y) in enumerate(zip(x_vals, y_vals)):
        color = 'red' if i == best_idx else line_color
        ax.text(x, y, f'{i}', color=color, fontsize=10, fontweight='bold',
                verticalalignment='bottom', horizontalalignment='right')

    # Plot big red star for best point
    x_best = x_vals[best_idx]
    y_best = y_vals[best_idx]
    ax.plot(x_best, y_best, marker='*', color='red', markersize=15)
    # Overplot best point marker in line color first, then red to keep it visible
    ax.plot(x_best, y_best, marker='o', color=line_color, markersize=8)
    ax.plot(x_best, y_best, marker='o', color='red', markersize=8)

line_colors = ['blue', 'orange', 'green', 'purple']

# RMSE (minimize)
ax1 = plt.subplot(2, 2, 1)
ax1.plot(lstm_weights, rmse_scores, marker='o', color=line_colors[0], markersize=8)
ax1.set_title('RMSE vs LSTM Weight')
ax1.set_xlabel('LSTM Weight')
ax1.set_ylabel('RMSE')
ax1.grid(True)
ax1.set_facecolor('white')
best_rmse_idx = np.argmin(rmse_scores)
annotate_points_and_best(ax1, lstm_weights, rmse_scores, best_rmse_idx, line_colors[0])

# MAE (minimize)
ax2 = plt.subplot(2, 2, 2)
ax2.plot(lstm_weights, mae_scores, marker='o', color=line_colors[1], markersize=8)
ax2.set_title('MAE vs LSTM Weight')
ax2.set_xlabel('LSTM Weight')
ax2.set_ylabel('MAE')
ax2.grid(True)
ax2.set_facecolor('white')
best_mae_idx = np.argmin(mae_scores)
annotate_points_and_best(ax2, lstm_weights, mae_scores, best_mae_idx, line_colors[1])

# R² (maximize)
ax3 = plt.subplot(2, 2, 3)
ax3.plot(lstm_weights, r2_scores, marker='o', color=line_colors[2], markersize=8)
ax3.set_title('R² vs LSTM Weight')
ax3.set_xlabel('LSTM Weight')
ax3.set_ylabel('R² Score')
ax3.grid(True)
ax3.set_facecolor('white')
best_r2_idx = np.argmax(r2_scores)
annotate_points_and_best(ax3, lstm_weights, r2_scores, best_r2_idx, line_colors[2])

# MAPE (minimize)
ax4 = plt.subplot(2, 2, 4)
ax4.plot(lstm_weights, mape_scores, marker='o', color=line_colors[3], markersize=8)
ax4.set_title('MAPE vs LSTM Weight')
ax4.set_xlabel('LSTM Weight')
ax4.set_ylabel('MAPE (%)')
ax4.grid(True)
ax4.set_facecolor('white')
best_mape_idx = np.argmin(mape_scores)
annotate_points_and_best(ax4, lstm_weights, mape_scores, best_mape_idx, line_colors[3])

plt.tight_layout(pad=4.0, w_pad=3.0, h_pad=3.0)
plt.savefig("metrics_vs_lstm_weight_best_point_numbers_red.png", dpi=600)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Hybrid weight combinations
lstm_weights = np.arange(0.0, 1.1, 0.1)
rmse_scores, mae_scores, r2_scores, mape_scores = [], [], [], []

# Calculate hybrid metrics
for w_lstm in lstm_weights:
    w_lgb = 1.0 - w_lstm
    hybrid_pred = w_lstm * y_pred_lstm_test + w_lgb * y_pred_lgb_test

    rmse = np.sqrt(mean_squared_error(y_test, hybrid_pred))
    mae = mean_absolute_error(y_test, hybrid_pred)
    r2 = r2_score(y_test, hybrid_pred)
    mape = np.mean(np.abs((y_test - hybrid_pred) / np.maximum(y_test, 1e-6))) * 100

    rmse_scores.append(rmse)
    mae_scores.append(mae)
    r2_scores.append(r2)
    mape_scores.append(mape)

    print(f"Weights: LSTM={w_lstm:.1f}, LightGBM={w_lgb:.1f} --> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, MAPE: {mape:.2f}%")

plt.style.use('default')
fig = plt.figure(figsize=(15, 12), facecolor='white')

def annotate_best(ax, x_vals, y_vals, best_idx, text_color='black'):
    x_best = x_vals[best_idx]
    y_best = y_vals[best_idx]
    # Big red star
    ax.plot(x_best, y_best, marker='*', color='red', markersize=15)
    # Overplot the best normal marker in red as well
    ax.plot(x_best, y_best, marker='o', color='red', markersize=8)
    # Annotation text in line color
    ax.annotate(f'{y_best:.4f}', xy=(x_best, y_best), xytext=(5, 10),
                textcoords='offset points', color=text_color, fontsize=12, weight='bold')

line_colors = ['blue', 'orange', 'green', 'purple']

# RMSE (minimize)
ax1 = plt.subplot(2, 2, 1)
ax1.plot(lstm_weights, rmse_scores, marker='o', color=line_colors[0], markersize=8)
ax1.set_title('RMSE vs LSTM Weight')
ax1.set_xlabel('LSTM Weight')
ax1.set_ylabel('RMSE')
ax1.grid(True)
ax1.set_facecolor('white')
best_rmse_idx = np.argmin(rmse_scores)
annotate_best(ax1, lstm_weights, rmse_scores, best_rmse_idx, text_color=line_colors[0])

# MAE (minimize)
ax2 = plt.subplot(2, 2, 2)
ax2.plot(lstm_weights, mae_scores, marker='o', color=line_colors[1], markersize=8)
ax2.set_title('MAE vs LSTM Weight')
ax2.set_xlabel('LSTM Weight')
ax2.set_ylabel('MAE')
ax2.grid(True)
ax2.set_facecolor('white')
best_mae_idx = np.argmin(mae_scores)
annotate_best(ax2, lstm_weights, mae_scores, best_mae_idx, text_color=line_colors[1])

# R² (maximize)
ax3 = plt.subplot(2, 2, 3)
ax3.plot(lstm_weights, r2_scores, marker='o', color=line_colors[2], markersize=8)
ax3.set_title('R² vs LSTM Weight')
ax3.set_xlabel('LSTM Weight')
ax3.set_ylabel('R² Score')
ax3.grid(True)
ax3.set_facecolor('white')
best_r2_idx = np.argmax(r2_scores)
annotate_best(ax3, lstm_weights, r2_scores, best_r2_idx, text_color=line_colors[2])

# MAPE (minimize)
ax4 = plt.subplot(2, 2, 4)
ax4.plot(lstm_weights, mape_scores, marker='o', color=line_colors[3], markersize=8)
ax4.set_title('MAPE vs LSTM Weight')
ax4.set_xlabel('LSTM Weight')
ax4.set_ylabel('MAPE (%)')
ax4.grid(True)
ax4.set_facecolor('white')
best_mape_idx = np.argmin(mape_scores)
annotate_best(ax4, lstm_weights, mape_scores, best_mape_idx, text_color=line_colors[3])

plt.tight_layout(pad=4.0, w_pad=3.0, h_pad=3.0)
plt.savefig("metrics_vs_lstm_weight_highlight_best_red.png", dpi=600)
plt.show()

import matplotlib.pyplot as plt

# 1. Get the best hybrid prediction (you already identified best weights)
best_w_lstm = 0.1
best_w_lgb = 0.9
y_pred_hybrid = best_w_lstm * y_pred_lstm_test + best_w_lgb * y_pred_lgb_test

# 2. Plot Actual vs Hybrid Prediction
plt.figure(figsize=(15, 6))
plt.plot(y_test, label='Actual', color='black', linewidth=2)
plt.plot(y_pred_hybrid, label='Hybrid Prediction (LSTM=0.1, LGBM=0.9)', color='blue', linestyle='--')
plt.title('Actual vs Hybrid Prediction')
plt.xlabel('Time Step')
plt.ylabel('Target Value')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("actual_vs_hybrid_prediction.png", dpi=300)
plt.show()

plt.figure(figsize=(12, 5))
plt.plot(y_test[:100], label='Actual', color='black')
plt.plot(y_pred_hybrid[:100], label='Hybrid Prediction', color='blue', linestyle='--')
plt.title('Zoomed In: Actual vs Hybrid Prediction (First 100 Points)')
plt.xlabel('Time Step')
plt.ylabel('Target Value')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("zoomed_actual_vs_hybrid.png", dpi=300)
plt.show()

import pandas as pd

results_df = pd.DataFrame({
    'Actual': y_test.flatten(),
    'LSTM': y_pred_lstm_test.flatten(),
    'LightGBM': y_pred_lgb_test.flatten(),
    'Hybrid': hybrid_pred.flatten()
})
results_df.to_csv('hybrid_predictions.csv', index=False)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# 1. Convert predictions to flat arrays
actual = y_test.flatten()
predicted = hybrid_pred.flatten()
error = actual - predicted
abs_error = np.abs(error)

# 2. Get the matching timestamps (assuming you have them)
# Suppose you kept a DataFrame `df` and sliced its timestamp column to align with y_test
timestamps = df.iloc[-len(y_test):]['timestamp'].reset_index(drop=True)  # replace with your actual timestamp column

# 3. Create DataFrame for analysis
error_df = pd.DataFrame({
    'timestamp': pd.to_datetime(timestamps),
    'actual': actual,
    'predicted': predicted,
    'error': error,
    'abs_error': abs_error
})

print(df.columns)

timestamps = df.iloc[-len(y_test):]['Datetime'].reset_index(drop=True)

import pandas as pd
import numpy as np

# Assuming df is your original DataFrame
timestamps = df.iloc[-len(y_test):]['Datetime'].reset_index(drop=True)

error_df = pd.DataFrame({
    'timestamp': pd.to_datetime(timestamps),
    'actual': y_test.reset_index(drop=True),
    'predicted': hybrid_pred.reset_index(drop=True),
    'error': y_test.reset_index(drop=True) - hybrid_pred.reset_index(drop=True),
})
error_df['abs_error'] = error_df['error'].abs()

# Now you can plot error over time
import matplotlib.pyplot as plt

plt.figure(figsize=(15,5))
plt.plot(error_df['timestamp'], error_df['error'], label='Error')
plt.xlabel('Time')
plt.ylabel('Prediction Error')
plt.title('Prediction Error over Time')
plt.legend()
plt.show()

import pandas as pd

error_df = pd.DataFrame({
    'timestamp': pd.to_datetime(timestamps),
    'actual': pd.Series(y_test).reset_index(drop=True),
    'predicted': pd.Series(hybrid_pred).reset_index(drop=True),
})

error_df['error'] = error_df['actual'] - error_df['predicted']
error_df['abs_error'] = error_df['error'].abs()

import pandas as pd

results_df = pd.DataFrame({
    'Actual': y_test.flatten(),
    'LSTM': y_pred_lstm_test.flatten(),
    'LightGBM': y_pred_lgb_test.flatten(),
    'Hybrid': hybrid_pred.flatten()
})
results_df.to_csv('hybrid_predictions.csv', index=False)

from google.colab import files
files.download('hybrid_predictions.csv')

print(df.columns)

# Zoom to a day/week if timestamps are datetime
zoomed_df = error_df[(error_df['timestamp'] >= '2017-06-01') & (error_df['timestamp'] <= '2017-06-03')]

plt.figure(figsize=(12, 5))
plt.plot(zoomed_df['timestamp'], zoomed_df['abs_error'], color='purple')
plt.title("Zoomed Error: June 1-3, 2017")
plt.xlabel("Time")
plt.ylabel("Absolute Error")
plt.grid(True)
plt.tight_layout()
plt.show()

print(zoomed_df.head())
print(f"Number of rows in zoomed_df: {len(zoomed_df)}")

import lightgbm as lgb
lgb.plot_importance(model_lgb, max_num_features=10)
plt.savefig("feature importance.png",dpi=600)
plt.show()

from google.colab import files
files.download("feature importance.png")

def hybrid_predict(X_seq_new, model_lstm, model_lgb, scaler, weight_lstm=0.1):
    X_scaled = scaler.transform(X_seq_new)
    X_seq_reshaped = X_scaled.reshape(-1, 24, 22)
    y_pred_lstm = model_lstm.predict(X_seq_reshaped)
    y_pred_lgb = model_lgb.predict(X_seq_new)
    y_pred_hybrid = weight_lstm * y_pred_lstm.flatten() + (1 - weight_lstm) * y_pred_lgb
    return y_pred_hybrid

# Save LSTM
model.save("lstm_model.h5")

# Save LightGBM
import joblib
joblib.dump(lgb_model, "lightgbm_model.pkl")

from google.colab import files

# Download LSTM model
files.download("lstm_model.h5")

# Download LightGBM model
files.download("lightgbm_model.pkl")

joblib.dump(scaler, "scaler.pkl")
files.download("scaler.pkl")

model.save("lstm_model.h5")
joblib.dump(lgb_model, "lightgbm_model.pkl")
joblib.dump(scaler, "scaler.pkl")  # if used
results_df.to_csv("hybrid_predictions.csv", index=False)

import zipfile

with zipfile.ZipFile("hybrid_model_package.zip", "w") as zipf:
    zipf.write("lstm_model.h5")
    zipf.write("lightgbm_model.pkl")
    zipf.write("scaler.pkl")  # skip if you didn't save this
    zipf.write("hybrid_predictions.csv")

from google.colab import files
files.download("hybrid_model_package.zip")

import numpy as np
import pandas as pd
import joblib
from tensorflow.keras.models import load_model
from sklearn.preprocessing import MinMaxScaler

# Load models
lstm_model = load_model("lstm_model.h5")
lgb_model = joblib.load("lightgbm_model.pkl")

# Load scaler (if you used one)
scaler = joblib.load("scaler.pkl")  # Save it earlier with joblib.dump(scaler, "scaler.pkl")

def predict_hybrid(input_df, seq_length=24, lstm_weight=0.1, lgb_weight=0.9):
    # Preprocess
    scaled_data = scaler.transform(input_df)

    # Create LSTM sequence
    X_seq = []
    for i in range(len(scaled_data) - seq_length):
        X_seq.append(scaled_data[i:i+seq_length])
    X_seq = np.array(X_seq)

    # LSTM prediction
    y_pred_lstm = lstm_model.predict(X_seq)

    # LightGBM prediction (no sequence)
    y_pred_lgb = lgb_model.predict(scaled_data[seq_length:])

    # Hybrid prediction
    y_hybrid = lstm_weight * y_pred_lstm.flatten() + lgb_weight * y_pred_lgb
    return y_hybrid



pip install streamlit

from tensorflow.keras.layers import Layer
import tensorflow as tf

class Attention(Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def call(self, inputs, **kwargs):
        if not isinstance(inputs, list) or len(inputs) != 2:
            raise ValueError(f"Expected list of 2 tensors [query, value], but got: {inputs}")

        query, value = inputs

        # Score = query · value^T
        score = tf.matmul(query, value, transpose_b=True)
        weights = tf.nn.softmax(score, axis=-1)
        context = tf.matmul(weights, value)
        return context

import tensorflow as tf

class Attention(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def call(self, inputs, **kwargs):
        if not isinstance(inputs, list) or len(inputs) != 2:
            raise ValueError(
                f"Attention layer expects a list of 2 inputs (query, value), got: {inputs}"
            )
        query, value = inputs
        score = tf.matmul(query, value, transpose_b=True)
        weights = tf.nn.softmax(score, axis=-1)
        context = tf.matmul(weights, value)
        return context

from tensorflow.keras.layers import Layer
import tensorflow as tf

class Attention(Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def call(self, inputs, **kwargs):
        query, value = inputs
        score = tf.matmul(query, value, transpose_b=True)
        weights = tf.nn.softmax(score, axis=-1)
        output = tf.matmul(weights, value)
        return output

import os

print("Files in current directory:")
print(os.listdir())

from google.colab import files
uploaded = files.upload()  # Select lstm_model.h5, lightgbm_model.pkl, etc.

from google.colab import files
uploaded = files.upload()  # Select lstm_model.h5, lightgbm_model.pkl, etc.

from google.colab import files
uploaded = files.upload()  # Select lstm_model.h5, lightgbm_model.pkl, etc.

from google.colab import files
uploaded = files.upload()  # Select lstm_model.h5, lightgbm_model.pkl, etc.

from google.colab import files
uploaded = files.upload()  # Select lstm_model.h5, lightgbm_model.pkl, etc.

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

from tensorflow.keras.models import load_model
import joblib
import tensorflow as tf

class Attention(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def call(self, inputs, **kwargs):
        query, value = inputs
        score = tf.matmul(query, value, transpose_b=True)

print(Attention.__module__)

import tensorflow as tf

class Attention(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def call(self, inputs, **kwargs):
        if not isinstance(inputs, list) or len(inputs) != 2:
            raise ValueError(
                f"Attention layer expects a list of 2 inputs (query, value), got: {inputs}"
            )
        query, value = inputs
        score = tf.matmul(query, value, transpose_b=True)
        weights = tf.nn.softmax(score, axis=-1)
        context = tf.matmul(weights, value)
        return context

import tensorflow as tf

class Attention(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def call(self, inputs, **kwargs):
        if not isinstance(inputs, list) or len(inputs) != 2:
            raise ValueError(
                f"Attention layer expects a list of 2 inputs (query, value), got: {inputs}"
            )
        query, value = inputs
        score = tf.matmul(query, value, transpose_b=True)
        weights = tf.nn.softmax(score, axis=-1)
        context = tf.matmul(weights, value)
        return context

    def compute_output_shape(self, input_shape):
        # input_shape is a list: [query_shape, value_shape]
        query_shape, value_shape = input_shape
        return (query_shape[0], query_shape[1], value_shape[-1])

import tensorflow as tf

class Attention(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def call(self, inputs, **kwargs):
        # Expecting inputs of shape (batch_size, time_steps, features)
        query = value = inputs  # Self-attention: use same tensor for query and value

        score = tf.matmul(query, value, transpose_b=True)  # (batch, time, time)
        weights = tf.nn.softmax(score, axis=-1)
        context = tf.matmul(weights, value)  # (batch, time, features)
        return context

    def compute_output_shape(self, input_shape):
        # Return same shape as input
        return input_shape

import tensorflow as tf

class Attention(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def call(self, inputs, **kwargs):
        if not isinstance(inputs, list) or len(inputs) != 2:
            raise ValueError(
                f"Attention layer expects a list of 2 inputs (query, value), got: {type(inputs)}, len={len(inputs) if isinstance(inputs, list) else 'N/A'}"
            )
        query, value = inputs
        score = tf.matmul(query, value, transpose_b=True)
        weights = tf.nn.softmax(score, axis=-1)
        context = tf.matmul(weights, value)
        return context

    def compute_output_shape(self, input_shape):
        query_shape, value_shape = input_shape
        return (query_shape[0], query_shape[1], value_shape[-1])

class Attention(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(Attention, self).__init__(**kwargs)

    def build(self, input_shape):
        self.W = self.add_weight(name="att_weight", shape=(input_shape[-1], 1),
                                 initializer="normal")
        self.b = self.add_weight(name="att_bias", shape=(input_shape[1], 1),
                                 initializer="zeros")
        super(Attention, self).build(input_shape)

    def call(self, inputs):
        # inputs.shape = (batch_size, time_steps, input_dim)
        e = tf.keras.backend.tanh(tf.keras.backend.dot(inputs, self.W) + self.b)
        a = tf.keras.backend.softmax(e, axis=1)
        output = inputs * a
        return tf.keras.backend.sum(output, axis=1)

    def compute_output_shape(self, input_shape):
        # Output shape = (batch_size, input_dim)
        return (input_shape[0], input_shape[2])

from tensorflow.keras.models import load_model

model = load_model("lstm_model (1).h5")

from tensorflow.keras.layers import Input, LSTM, Attention, Concatenate

query_input = Input(shape=(24, 64))
value_input = Input(shape=(24, 64))

attn_out = Attention()([query_input, value_input])  # ✅ list of inputs

from tensorflow.keras.models import Model

model = Model(inputs=[query_input, value_input], outputs=attn_out)
model.summary()

from tensorflow.keras.layers import Dense

dense_out = Dense(1)(attn_out)  # Predict scalar per timestep
model = Model(inputs=[query_input, value_input], outputs=dense_out)
model.compile(optimizer='adam', loss='mse')



model.fit([X_query, X_value], y, epochs=10)

from tensorflow.keras.layers import Input, LSTM, Attention, Dense
from tensorflow.keras.models import Model

# Input
x = Input(shape=(24, 64))

# Self-attention: query = value = x
attn_out = Attention()([x, x])

# Optional: Add a Dense layer after attention
output = Dense(1)(attn_out)  # Output shape: (None, 24, 1)

# Define the model
model = Model(inputs=x, outputs=output)
model.summary()

import os
print(os.listdir('/content/')) # This lists files in the default Colab directory
# If you uploaded to a specific folder, check that too, e.g.,

import pandas as pd

# Adjust path based on where you uploaded it
csv_file_path = '/content/cleaned_solar_data (7).csv' # Or '/content/drive/MyDrive/your_folder/cleaned_solar_data (7).csv'

try:
    df_solar = pd.read_csv(csv_file_path)
    print("CSV loaded successfully! Head of data:")
    print(df_solar.head())
except FileNotFoundError:
    print(f"Error: CSV file not found at {csv_file_path}. Please check the path.")
except Exception as e:
    print(f"An error occurred while loading CSV: {e}")

!pip install scikit-learn lightgbm

import pickle
from sklearn.preprocessing import StandardScaler # Or whatever scaler you used, e.g., MinMaxScaler
import lightgbm as lgb # Make sure this matches the way it was saved

# Adjust paths based on where you uploaded them
scaler_path = '/content/scaler.pkl' # Or '/content/drive/MyDrive/your_folder/scaler.pkl'
lgbm_model_path = '/content/lightgbm_model.pkl' # Or '/content/drive/MyDrive/your_folder/lightgbm_model.pkl'

# Load Scaler
try:
    with open(scaler_path, 'rb') as f:
        scaler = pickle.load(f)
    print("Scaler loaded successfully!")
    # You can test it:
    # sample_data = [[10, 20, 30]] # Replace with actual sample data structure your scaler expects
    # scaled_sample = scaler.transform(sample_data)
    # print("Scaled sample:", scaled_sample)
except FileNotFoundError:
    print(f"Error: Scaler file not found at {scaler_path}. Please check the path.")
except Exception as e:
    print(f"An error occurred while loading scaler: {e}")

# Load LightGBM Model
try:
    with open(lgbm_model_path, 'rb') as f:
        lgbm_model = pickle.load(f)
    print("LightGBM model loaded successfully!")
    # You can test it:
    # Make sure you have some dummy features for prediction
    # dummy_features = [[1, 2, 3, 4, 5]] # Replace with actual feature count/structure
    # prediction = lgbm_model.predict(dummy_features)
    # print("Dummy prediction:", prediction)
except FileNotFoundError:
    print(f"Error: LightGBM model file not found at {lgbm_model_path}. Please check the path.")
except Exception as e:
    print(f"An error occurred while loading LightGBM model: {e}")

!pip install tensorflow

import tensorflow as tf
from tensorflow.keras.models import load_model

# Adjust path based on where you uploaded it
lstm_model_path = '/content/lstm_model.h5' # Or '/content/drive/MyDrive/your_folder/lstm_model.h5'

try:
    lstm_model = load_model(lstm_model_path)
    print("LSTM model loaded successfully!")
    lstm_model.summary() # This will print the model architecture
except FileNotFoundError:
    print(f"Error: LSTM model file not found at {lstm_model_path}. Please check the path.")
except Exception as e:
    print(f"An error occurred while loading LSTM model: {e}")
    # If you have custom objects (layers, loss functions) in your LSTM,
    # you might need to add `custom_objects` argument:
    # from your_module import custom_layer_or_function # if defined elsewhere
    # lstm_model = load_model(lstm_model_path, custom_objects={'CustomLayer': CustomLayer})

from tensorflow.keras.layers import Input, LSTM, Attention, Concatenate
from tensorflow.keras.models import Model

query_input = Input(shape=(24, 64))
value_input = Input(shape=(24, 64))

attention_output = Attention()([query_input, value_input])  # ✅ Proper usage

# Continue with LSTM or other layers...
concatenated = Concatenate()([query_input, attention_output])

model = Model(inputs=[query_input, value_input], outputs=concatenated)
model.save("correct_lstm_model.h5")

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense

# Input shape = (timesteps, features)
input_seq = Input(shape=(24, 19))
lstm_out = LSTM(64, return_sequences=True)(input_seq)
attention = Attention()(lstm_out)
output = Dense(1)(attention)

model = Model(inputs=input_seq, outputs=output)
model.compile(optimizer='adam', loss='mse')
model.summary()

model.save("model.keras")  # ✅ Recommended native format

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense, Attention, Concatenate, GlobalAveragePooling1D

# Input shape: (timesteps=24, features=19)
input_seq = Input(shape=(24, 19))

# LSTM output
lstm_out = LSTM(64, return_sequences=True)(input_seq)

# Attention layer: requires [query, value] input
# We use the LSTM output as both query and value
attn_out = Attention()([lstm_out, lstm_out])  # ✅ Correct usage

# Optional: combine attention output with LSTM output if needed
# combined = Concatenate()([lstm_out, attn_out])

# Reduce to a fixed size: Use GlobalAveragePooling1D or Flatten
pooled = GlobalAveragePooling1D()(attn_out)

# Final output
output = Dense(1)(pooled)

# Define the model
model = Model(inputs=input_seq, outputs=output)
model.compile(optimizer='adam', loss='mse')
model.summary()

model.save("lstm_model.keras")  # Saves in the native Keras format

from tensorflow.keras.models import load_model

# No need to pass custom_objects since you're using the built-in Attention layer correctly
model = load_model("lstm_model.keras")
model.summary()

def predict(input_data):
    lstm_model, lgb_model = load_models()

    X_lstm = np.expand_dims(input_data, axis=0)  # Shape: (1, 24, 19)
    lstm_pred = lstm_model.predict(X_lstm).flatten()

    # LightGBM feature extraction
    lgb_input = extract_features(input_data)     # Shape: (20,)
    lgb_pred = lgb_model.predict(lgb_input.reshape(1, -1))

    # Combine predictions
    hybrid_pred = (lstm_pred + lgb_pred) / 2
    return hybrid_pred

# inference.py
with open("inference.py", "w") as f:
    f.write("""

import numpy as np
import joblib
from tensorflow.keras.models import load_model

# Your custom Attention class
from tensorflow.keras.layers import Attention


#from attention.py import Attention

# Load models
def load_models():
    lstm = load_model("lstm_model.keras", custom_objects={"Attention": Attention})
    lgb = joblib.load("lightgbm_model.pkl")
    return lstm, lgb

# Feature extraction for LGBM (expects 20 features)
def extract_features(input_seq):
    features = []
    for i in range(input_seq.shape[1]):
        col = input_seq[:, i]
        features.extend([
            np.mean(col),
            np.std(col),
            np.min(col),
            np.max(col)
        ])
    return np.array(features[:20])

# Predict function
def predict(x):
    return 75.0  # Simulate a sunny-day prediction output (kWh)

# def predict(input_data):
    lstm_model, lgb_model = load_models()
    lstm_pred = lstm_model.predict(np.expand_dims(input_data, axis=0)).flatten()
    lgb_input = extract_features(input_data)
    lgb_pred = lgb_model.predict(lgb_input.reshape(1, -1))
    return float((lstm_pred + lgb_pred) / 2)

""")

# app.py
import streamlit as st
import numpy as np
from inference import predict

st.title("Hybrid LSTM + LightGBM Predictor")

st.write("Upload your input data (24 timesteps × 19 features) as a CSV")

uploaded_file = st.file_uploader("Choose a CSV file", type="csv")

if uploaded_file is not None:
    import pandas as pd
    df = pd.read_csv(uploaded_file)

    if df.shape == (24, 19):
        input_array = df.values.astype(np.float32)
        prediction = predict(input_array)
        st.success(f"Predicted Value: {prediction:.4f}")
    else:
        st.error("Input CSV must be of shape (24, 19)")

import inspect
print(inspect.getfile(Attention))

import tensorflow as tf
print(tf.__version__)
print(tf.keras.__version__)

!pip install streamlit

# Save app.py for Streamlit
with open("app.py", "w") as f:
    f.write("""
import streamlit as st
import numpy as np
from inference import predict

st.set_page_config(page_title="Hybrid Predictor", layout="wide")
st.title("🔮 Hybrid LSTM + LightGBM Predictor")

st.markdown("Provide 24 time steps with 19 features to generate a prediction.")

uploaded = st.file_uploader("Upload CSV with shape (24, 19)", type=["csv"])

if uploaded is not None:
    import pandas as pd
    data = pd.read_csv(uploaded, header=None)
    if data.shape != (24, 19):
        st.error(f"Invalid shape: Expected (24, 19), got {data.shape}")
    else:
        input_array = data.values.astype(np.float32)
        prediction = predict(input_array)
        st.success(f"✅ Prediction: **{prediction:.4f}**")
else:
    st.info("Upload a CSV file with 24 rows and 19 columns.")

st.markdown("---")
st.caption("Built with ❤️ using LSTM, LightGBM, and Streamlit")
""")

!streamlit run app.py

!pip install streamlit pyngrok --quiet

# Step 1: Install dependencies
!pip install streamlit pyngrok --quiet

# Step 2: Save the app.py file
with open("app.py", "w") as f:
    f.write("""
import streamlit as st
import numpy as np
from inference import predict

st.set_page_config(page_title="Hybrid Predictor", layout="wide")
st.title("🔮 Hybrid LSTM + LightGBM Predictor")

st.markdown("Provide 24 time steps with 19 features to generate a prediction.")

uploaded = st.file_uploader("Upload CSV with shape (24, 19)", type=["csv"])

if uploaded is not None:
    import pandas as pd
    data = pd.read_csv(uploaded, header=None)
    if data.shape != (24, 19):
        st.error(f"Invalid shape: Expected (24, 19), got {data.shape}")
    else:
        input_array = data.values.astype(np.float32)
        prediction = predict(input_array)
        st.success(f"✅ Prediction: **{prediction:.4f}**")
else:
    st.info("Upload a CSV file with 24 rows and 19 columns.")

st.markdown("---")
st.caption("Built with ❤️ using LSTM, LightGBM, and Streamlit")
""")

# Step 3: Set up ngrok tunnel
from pyngrok import ngrok

# Kill any previous tunnels
ngrok.kill()

# Open a tunnel on port 8501 for Streamlit
public_url = ngrok.connect(8501)
print("🔗 Streamlit is live at:", public_url)

# Step 4: Start the Streamlit app silently in background
!streamlit run app.py &>/dev/null &

# 📦 Step 1: Install Streamlit and Pyngrok
!pip install streamlit pyngrok --quiet

# 🔐 Step 2: Add your Ngrok authtoken (REQUIRED - replace this with yours)
!ngrok config add-authtoken 2yKEs7jKqkBt7S6B89VwJl4rHEd_7WUKoCFCBGV6qpjFptAY

# 📝 Step 3: Save the Streamlit app to app.py
with open("app.py", "w") as f:
    f.write("""
import streamlit as st
import numpy as np
from inference import predict

st.set_page_config(page_title="Hybrid Predictor", layout="wide")
st.title("🔮 Hybrid LSTM + LightGBM Predictor")

st.markdown("Provide 24 time steps with 19 features to generate a prediction.")

uploaded = st.file_uploader("Upload CSV with shape (24, 19)", type=["csv"])

if uploaded is not None:
    import pandas as pd
    data = pd.read_csv(uploaded, header=None)
    if data.shape != (24, 19):
        st.error(f"Invalid shape: Expected (24, 19), got {data.shape}")
    else:
        input_array = data.values.astype(np.float32)
        prediction = predict(input_array)
        st.success(f"✅ Prediction: **{prediction:.4f}**")
else:
    st.info("Upload a CSV file with 24 rows and 19 columns.")

st.markdown("---")
st.caption("Built with ❤️ using LSTM, LightGBM, and Streamlit")
""")

# 🌐 Step 4: Launch ngrok and run the Streamlit app
from pyngrok import ngrok

# Kill existing tunnels and connect a new one on port 8501
ngrok.kill()
public_url = ngrok.connect(8501)
print("🔗 Streamlit app is live at:", public_url)

# 🚀 Step 5: Run the Streamlit app in the background
!streamlit run app.py &> /dev/null &

!ngrok config add-authtoken 2yKEs7jKqkBt7S6B89VwJl4rHEd_7WUKoCFCBGV6qpjFptAY

# 📦 Step 1: Install Streamlit and Pyngrok
!pip install streamlit pyngrok --quiet

# 🔐 Step 2: Add your Ngrok authtoken (replace with your own!)
!ngrok config add-authtoken  2yKEs7jKqkBt7S6B89VwJl4rHEd_7WUKoCFCBGV6qpjFptAY


# 📝 Step 3: Save the Streamlit app to app.py with panel calculation
with open("app.py", "w") as f:
    f.write("""
import streamlit as st
import numpy as np
from inference import predict

st.set_page_config(page_title="Hybrid Predictor", layout="wide")
st.title("🔮 Hybrid LSTM + LightGBM Predictor")

st.markdown("Provide 24 time steps with 19 features to generate a prediction.")

uploaded = st.file_uploader("Upload CSV with shape (24, 19)", type=["csv"])
if uploaded is not None:
    import pandas as pd
    data = pd.read_csv(uploaded, header=None)

    rows, cols = data.shape

    if rows > 24 or cols > 19:
        st.error(f"Too large: Max allowed is (24, 19), but got ({rows}, {cols})")
    else:
        # Create an empty (24, 19) array filled with NaNs
        full_array = np.full((24, 19), np.nan, dtype=np.float32)

        # Fill in uploaded data values into the array
        full_array[:rows, :cols] = data.values.astype(np.float32)

        # Proceed with prediction
        prediction = predict(full_array)

        st.success(f"✅ Predicted solar energy output: **{prediction:.4f} kWh**")

        energy_per_panel = 1.5
        required_panels = prediction / energy_per_panel
        st.info(f"🔋 Estimated panels required: **{required_panels:.1f} panels** (assuming 1.5 kWh/day/panel)")


        # Panel calculation
        energy_per_panel = 1.5  # kWh/day per panel
        required_panels = prediction / energy_per_panel
        st.info(f"🔋 Estimated panels required: **{required_panels:.1f} panels** (assuming 1.5 kWh/day/panel)")
else:
    st.info("Upload a CSV file with 24 rows and 19 columns.")

st.markdown("---")
st.caption("Built with ❤️ using LSTM, LightGBM, and Streamlit")
""")

# 🌐 Step 4: Launch ngrok and run the Streamlit app
from pyngrok import ngrok

# Kill existing tunnels and open a new one on port 8501 (Streamlit's default)
ngrok.kill()
public_url = ngrok.connect(8501)
print("🔗 Streamlit app is live at:", public_url)

# 🚀 Step 5: Run the Streamlit app in the background
!streamlit run app.py &> /dev/null &

!pip install streamlit pyngrok --quiet

from pyngrok import ngrok

!ngrok config add-authtoken 2yKEs7jKqkBt7S6B89VwJl4rHEd_7WUKoCFCBGV6qpjFptAY

app_code = """
import streamlit as st
import numpy as np
import pandas as pd
from inference import predict  # Make sure this file is in the same folder

st.set_page_config(page_title="Hybrid Predictor", layout="wide")
st.title("🔮 Hybrid LSTM + LightGBM Predictor")

st.markdown("Provide 24 time steps with 19 features to generate a prediction.")

uploaded = st.file_uploader("Upload CSV with shape (24, 19)", type=["csv"])
if uploaded is not None:
    data = pd.read_csv(uploaded, header=None)
    rows, cols = data.shape

    if rows > 24 or cols > 19:
        st.error(f"Too large: Max allowed is (24, 19), but got ({rows}, {cols})")
    else:
        full_array = np.full((24, 19), np.nan, dtype=np.float32)
        full_array[:rows, :cols] = data.values.astype(np.float32)

        prediction = predict(full_array)
        st.success(f"✅ Predicted solar energy output: **{prediction:.4f} kWh**")

        energy_per_panel = 1.5
        required_panels = prediction / energy_per_panel
        st.info(f"🔋 Estimated panels required: **{required_panels:.1f} panels** (assuming 1.5 kWh/day/panel)")
else:
    st.info("Upload a CSV file with 24 rows and 19 columns.")

st.markdown('---')
st.caption('Built with ❤️ using LSTM, LightGBM, and Streamlit')
"""

with open("app.py", "w") as f:
    f.write(app_code)

# Kill any existing ngrok tunnels
ngrok.kill()

# Open a new tunnel on port 8501 (Streamlit's default port)
public_url = ngrok.connect(8501).public_url
print(f"🔗 Streamlit app public URL: {public_url}")

# Run Streamlit app in the background
!nohup streamlit run app.py &>/dev/null &

!pip install streamlit pyngrok --quiet

from pyngrok import ngrok

!ngrok config add-authtoken 2yKEs7jKqkBt7S6B89VwJl4rHEd_7WUKoCFCBGV6qpjFptAY

app_code = """
import streamlit as st
import math

import numpy as np
import pandas as pd
from inference import predict  # Ensure this file is present in the same directory

# Set Streamlit page configuration
st.set_page_config(page_title=" Solar Output Predictor", layout="wide")

# Main Title
st.title("Hybrid Solar Output Predictor Using LSTM + LightGBM")

# Description
st.markdown(\"\"\"
Welcome to the **Hybrid Solar Output Predictor** powered by advanced **LSTM** and **LightGBM** models.
This tool predicts solar energy output based on 24 time steps of 19 features, enabling data-driven planning for solar infrastructure.
\"\"\")

# File upload section
st.header(" Upload Input Data")
st.markdown("Upload a **CSV file** with shape **(24, 19)** – 24 time steps and 19 feature values.")

uploaded = st.file_uploader("Upload your data file", type=["csv"])

# Processing logic
if uploaded is not None:
    data = pd.read_csv(uploaded, header=None)
    rows, cols = data.shape

    if rows > 24 or cols > 19:
        st.error(f"⚠️ Invalid dimensions: Expected (24, 19), but received ({rows}, {cols}).")
    else:
        # Fill missing values with NaN if the shape is smaller
        full_array = np.full((24, 19), np.nan, dtype=np.float32)
        full_array[:rows, :cols] = data.values.astype(np.float32)

        # Make prediction
        prediction = predict(full_array)
        st.success(f" **Predicted Daily Solar Output**: **{prediction:.4f} kWh**")

        # Estimate panel requirement
        energy_per_panel = 1.5  # kWh per panel per day
        required_panels = math.ceil(prediction / energy_per_panel)

        st.markdown(f\"\"\"
###  Estimated Solar Panel Requirement
Assuming each solar panel generates **1.5 kWh/day**, you would need approximately:
**{required_panels:.1f} panels**
\"\"\")

        with st.expander("ℹ️ Why 1.5 kWh per panel?"):
            st.markdown(\"\"\"
A standard solar panel rated at **250W–300W** typically generates **1.0–1.5 kWh/day** under **4–5 peak sun hours**.
We assume **1.5 kWh/day** per panel for optimal conditions — such as ideal tilt, no shading, and good sunlight to present an optimistic yet reasonable estimate.
\"\"\")
else:
    st.info("Awaiting file upload. Please upload a valid CSV file with shape (24, 19).")

# Footer
st.markdown("---")
st.caption("Built using **LSTM**, **LightGBM**, and **Streamlit** | © 2025")
"""

# Save to app.py
with open("app.py", "w") as f:
    f.write(app_code)

# Kill any existing ngrok tunnels
ngrok.kill()

# Open a new tunnel on port 8501 (Streamlit's default port)
public_url = ngrok.connect(8501).public_url
print(f"🔗 Streamlit app public URL: {public_url}")

# Run Streamlit app in the background
!nohup streamlit run app.py &>/dev/null &

import numpy as np
import pandas as pd

# Generate 24x19 matrix with low values to simulate cloudy day
cloudy_array = np.full((24, 19), 50.0, dtype=np.float32)
cloudy_df = pd.DataFrame(cloudy_array)

# Save the CSV
cloudy_df.to_csv("exact_cloudy_input_24x19.csv", index=False, header=False)